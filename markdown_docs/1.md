## **KEY HISTORICAL DEVELOPMENTS** 

1943 - Warren McCulloch & Walter Pitts proposed a model of computing element, called MP neuron, which could perform weighted sum of inputs followed by a threshold logic operation. 

Advantage: Combination of these computing elements were used to realize logical computations. 

Drawback: Lack of learning i.e., weights are fixed, hence model could not learn from examples. ………….contd……… 

**==> picture [298 x 186] intentionally omitted <==**

--- end of page.page_number=1 ---

1949 - Donald Hebb proposed a learning scheme based on pre & post synaptic values of the variables (became a fundamental learning rule). 

1954 – Learning machine was developed by Marvin Minsky. In this connection strengths were adapted automatically. 

1958 – Rosenblatt proposed Perceptron model. Features: ▪ Adjusts weights by Perceptron Learning Law. ▪ Learning law converge for pattern classification problems, which are linearly separable in feature space. ▪ A single layer of perceptrons could handle only linearly separable classes, multilayer perceptron could be used to perform any pattern classification task. 

▪ Drawback – No systematic learning algorithm for weight adjustment in classification task. 

…………….contd……… 

--- end of page.page_number=2 ---

1960 – Widrow & Hoff, proposed Adaline Model. ▪ Used LMS learning to adjust weights. ▪ Convergence of LMS algorithm was proved. ▪ Successfully used for Adaptive Signal Processing. 

1969 – Minsky & Papert, demonstrated limitations of Perceptron model (No learning law for MLP). 

1974 – Werbos, introduced the concept of error back-propagation. 1982-84 – John Hopfield, published the energy analysis of feedback neural networks. Authors Shown the existence of stable equilibrium states in network provided, ▪ Network has symmetric weights & ▪ State update is made asynchronously. 

--- end of page.page_number=3 ---

1985 – Ackley, Hinton & Sejnowski, proposed 

▪ Boltzmann Machine (BM) - a feedback neural network with stochastic neuron units. 

▪ Stochastic neuron has an output function implemented using probabilistic update rule, instead of deterministic update rule in Hopfield Model. 

▪ Stochastic neuron has an output function implemented using probabilistic update rule, instead of deterministic update rule in Hopfield Model. ▪ BM has several additional neuron units, called Hidden units. 1986 – Rumelhart. Hinton & Williams, proposed a learning law called Generalised Delta Rule/ Error Backpropagation Learning Law, according to which, ▪ It is possible to adjust the weights of a multilayer feedforward neural network. 

………………..contd……. 

--- end of page.page_number=4 ---

## **Other Significant Contributions** 

1971 • Associative Memories by Kohonen. • Self Organization & Generalization by Willshaw 

1976 – Adaptive Resonance Theory (ART) by Grossberg. 1982 – Feature Mapping by Kohonen, SOMs (Self Organizing Maps) 1983 – Reinforcement Learning by Barto, Sutton & Anderson. 

1988 ▪ BAM (Bidirectional Associative memory) & Fuzzy Logic in ANN by Kosko. ▪ Radial Basis Functions (RBF) by Broomhead. 

--- end of page.page_number=5 ---

# **AGENT** is anything that perceives it environment through sensors and act that environment upon through actuators. 

**==> picture [606 x 351] intentionally omitted <==**

--- end of page.page_number=6 ---

**==> picture [608 x 389] intentionally omitted <==**

--- end of page.page_number=7 ---

**==> picture [595 x 395] intentionally omitted <==**

--- end of page.page_number=8 ---

**==> picture [576 x 396] intentionally omitted <==**

--- end of page.page_number=9 ---

**==> picture [604 x 403] intentionally omitted <==**

--- end of page.page_number=10 ---

## **LEARNING AGENT** 

**==> picture [622 x 406] intentionally omitted <==**

--- end of page.page_number=11 ---

## **Hybrid AI Agents** 

**(Best of all worlds)** 

- Real-world problems rarely fit neatly into one method, that’s where hybrid agents shine. These agents combine different architectures (reactive, goalbased, utility-based, learning, etc.) into a cohesive system that can operate flexibly under diverse conditions. 

- Core characteristics: 

**1. Architectural fusion:** Mix multiple agent types to harness the strengths of each. 

**2. Adaptive control:** Switch between decision strategies based on situation and need. 

      - between 

**3. Improved fault tolerance:** Redundancy and diversity of models reduce failure risk. 

   - **tolerance:** 

**4. Custom-built for complexity:** Ideal for domains that demand robustness, such as military AI, autonomous systems, or large-scale automation. 

**==> picture [386 x 293] intentionally omitted <==**

Hybrid AI agents are the Swiss Army knives of AI, versatile, resilient, and tailored to navigate the messiness of real-world decision-making 

--- end of page.page_number=12 ---

**==> picture [491 x 344] intentionally omitted <==**

--- end of page.page_number=13 ---

- **LEARNING IN ANN** 

- Learning process implies three sequence of events: 

- Neural network is stimulated by environment. 

- Neural network undergoes changes in free parameters as a result of this stimulation. 

- Neural network responds in a new way to the environment due to the changes that have occurred in its internal structure. 

--- end of page.page_number=14 ---

## **Definition & Facts Of Learning** 

Learning is a process by which free parameters of a neural network are adapted through a process of stimulation by the environment in which network is embedded. This type of learning is determined by the manner in which parameter changes take place. 

Learning is a slow process, & samples containing a pattern may have to be presented to the network many times before pattern information is captured by weights of the networks 

A large number of samples are needed for a network to learn. Network learns from example, not store examples themselves. 

--- end of page.page_number=15 ---

**Learning Algorithm** 

- Is a prescribed set of well-defined rules for the solution of learning problem. 

- There is no unique learning algorithm for the design of NNs. 

- • Learning algorithms differ from each other in a way in which adjustment to synaptic weight of a neuron is formulated. 

**Learning Equation** 

- Adjustment of synaptic weights is called Learning Equation, which describes synaptic dynamics of the network. 

**Learning Law** 

- Learning Law refers to the manner in which Learning Equations are implemented. 

• Depending on synaptic dynamics several learning laws are proposed. 

--- end of page.page_number=16 ---

   - **Requirements Of Learning Laws** 

- Learning Laws should lead to convergence of weights. 

- Learning/Training time for capturing the pattern information from samples should be as small as possible. 

- Online learning is preferable to an offline learning. 

- Learning should use only local information as far as possible, to speed up learning. 

• Learning should be able to capture complex nonlinear mapping between input-output pattern pairs, as well as between adjacent patterns in a temporal sequence of patterns. 

- Learning should be able to capture as many patterns as possible into the network, i.e., large pattern information storage capacity. 

--- end of page.page_number=17 ---

## **Supervised Learning** 

• **Definition: Learning from labeled datasets where each input has a known output.** 

- **Key Characteristics:** 

   - Input-output mapping 

   - Requires labeled data 

- **Advantages:** 

   - High accuracy with enough data 

   - Widely applicable 

- **Limitations:** 

   - Expensive labeling process 

   - Poor generalization outside 

      - distribution 

- **Examples & Applications:** 

   - Spam detection 

   - Medical diagnosis 

- **Algorithms:** 

   - Linear Regression 

   - Logistic Regression 

   - Decision Trees 

   - SVM (Support Vector Machines) 

   - • Back Propagation Neural Networks 

- **Trends:** 

• Large-scale supervised pretraining (a model is first trained on a very big labeled dataset (like millions of labeled images in ImageNet) so it learns general patterns. Later, the same model is fine-tuned on a smaller labeled dataset for a specific task (like traffic image classification). 

--- end of page.page_number=18 ---

## **Block Diagram Of Supervised Learning** 

**==> picture [409 x 302] intentionally omitted <==**

- It is a closed loop feedback system. 

- Error correction process is repeated to minimize error. 

• Number of iterations & reaching of a global or local minimum depends on learning algorithm used. 

--- end of page.page_number=19 ---

## **Unsupervised Learning** 

• **Definition: Learning without labeled data to find hidden patterns or structures.** 

## • **Key Characteristics:** 

- Clustering 

- Dimensionality reduction 

## • **Advantages:** 

- No need for labeled data 

- Useful for exploratory analysis 

## • **Limitations:** 

   - Hard to evaluate 

- **Examples & Applications:** 

   - Market segmentation 

   - Anomaly detection 

## • **Algorithms:** 

   - K-Means Clustering 

   - DBSCAN (Density-Based Spatial Clustering of Applications with Noise) 

   - PCA (Principal Component Analysis) is linear, statistical method. 

   - Autoencoders are nonlinear, neural network-based, more flexible. They learn to pack data into a smaller box (encoder) and then unpack it back 

      - (decoder). 

   - Variants of Decision Trees ( _clustering trees_ or _unsupervised decision trees)_ 

- **Trends:** 

- Self-supervised pretraining SelfSupervised Learning (SSL) is a type of unsupervised learning where the model learns useful representations without requiring human-labeled data. 

--- end of page.page_number=20 ---

## **Block Diagram Of Unsupervised Learning** 

**==> picture [441 x 265] intentionally omitted <==**

• During training network receive different input excitations & arbitrarily organizes the patterns into categories; i.e., the net adapts itself to align its weight values with training patterns • Also called Self Organized learning. 

--- end of page.page_number=21 ---

## **Semi-Supervised Learning** 

- **Definition: Combines a small set of labeled data with a large set of unlabeled data.** 

- **Key Characteristics:** 

   - Leverages unlabeled data 

- **Advantages:** 

   - Reduces labeling cost 

- **Limitations:** 

   - Sensitive to incorrect pseudo-labeling 

- **Examples & Applications:** 

   - Speech recognition 

   - Bioinformatics 

- **Trends:** 

   - Widely used in NLP and CV 

• Semi-Supervised Learning is a way of training a model when we have only a few labeled examples but a lot of unlabeled data. • First, the model learns from the small labeled dataset, just like in normal supervised learning. 

- Then, it looks at the large unlabeled dataset 

and tries to guess the missing labels on its own. These guessed labels, called _pseudolabels_ , are not perfect but they help the model practice more. 

• The model also checks if its predictions stay consistent even when the data is changed slightly, for example by rotating an image or rephrasing a sentence. 

• By combining the real labels with these guessed labels, the model becomes smarter, learns patterns more deeply, and finally gives better results than using only the small labeled se 

--- end of page.page_number=22 ---

## **Block Diagram Of Semi-Supervised Learning** 

**==> picture [615 x 440] intentionally omitted <==**

--- end of page.page_number=23 ---

## **Self-Supervised Learning** 

• Self-Supervised Learning starts with a large amount of unlabeled data (like text, images, or audio). 

**==> picture [409 x 435] intentionally omitted <==**

• Instead of needing humanmade labels, the model creates its own practice problems from the data — for example, guessing missing words in a sentence or predicting a hidden part of an image. • By solving these practice problems, the model learns useful patterns and features. Later, with just a small amount of labeled data, it can be fine-tuned for real tasks such as classification or recognition. • The final result is a powerful model that performs well, saves time, and reduces the need for costly labeling. 

--- end of page.page_number=24 ---

## **Self-Supervised Learning** 

## • **Definition: Learns from raw data by creating its own labels (pretext tasks)** • **Key Characteristics:** • Data-efficient 

- **Examples & Applications:** 

   - **GPT** (Generative Pre-trained Transformer) - 

   - It is a Large Language Model (LLM) that can understand and generate human-like text. 

   - **BERT** (Bidirectional Encoder 

   - Representations from Transformers)- It is a pre-trained language model designed to deeply understand the context of words in a sentence. Unlike GPT (which is unidirectional → left-to-right), BERT is bidirectional, meaning it looks at both left and right context simultaneously. 

   - **Vision Transformers** (class of deep learning 

models that apply the Transformer architecture (originally designed for NLP) to computer vision tasks such as image classification, detection, and segmentation • **Advantages:** 

   - No manual labels needed 

   - Scales to huge datasets 

- **Limitations:** 

   - Needs powerful compute 

- **Algorithms:** 

- • **Contrastive learning** (model learns by comparing data samples. The idea is to bring similar samples closer in the embedding space and push dissimilar ones farther apart.) 

- Example: Two photos of the same person should be close, while a photo of you and a photo of your friend should be far apart 

• **Masked prediction** (It refers to a learning technique where some part of the input (word, pixel, token, feature) is hidden (masked), and the model is trained to predict the missing part. Sentence: _“I like to eat [MASK].”_ The model learns to predict the missing word → _“ ”_ Chocolates . 

- **Trends:** 

**Foundation models** - These Models are largescale AI models trained on massive amounts of diverse data (text, images, audio, video, etc.) that can be adapted (fine-tuned) for a wide variety of downstream tasks. They are called _foundation_ because they act like a base layer — a starting point upon which many specialized applications can be built. 

--- end of page.page_number=25 ---

|**Aspect**|**BERT**|**GPT**|
|---|---|---|
|**Full Form**|Bidirectional Encoder Representations from<br>Transformers|Generative Pre-trained Transformer|
|**Architecture**|Encoder-only part of Transformer|Decoder-only part of Transformer|
|**Directionality**|Bidirectional (sees left + right context<br>together)|Unidirectional / autoregressive (left → right<br>prediction)|
|**Pretraining Objectives**|1. Masked Language Modeling (MLM) 2. Next<br>Sentence Prediction(NSP)|Next Word Prediction (causal language<br>modeling)|
|**Focus**|Language understanding (deep contextual<br>embeddings)|Language generation (text continuation,<br>story/chat)|
|**Input/Output**|Input sentence(s) → contextual embeddings<br>for each token|Input prompt → generates tokens step by<br>step|
|**Fine-tuning Tasks**|Classification (sentiment), NER (Named Entity<br>Recognition, QA, entailment (is a sentence<br>pair classification task), sentence similarity|<br>Text generation, summarization, dialogue,<br>code writing|
|**Examples**|BERT-base (12 layers, 110M parameters)<br>BERT-large(24 layers, 340Mparameters)|GPT-2 (1.5B parameters), GPT-3 (175B),<br>GPT-4, GPT-5|
|**Training Data Style**|Pretrained on Book Corpus + English<br>Wikipedia(2018)|Trained on massive internet text (web<br>pages, books, code, etc.)|
|**Handling Sentences**|Special token [CLS- Classification] for<br>sentence-level tasks, [SEP- Separator] for<br>separating two sentences|Doesn’t use [CLS]/[SEP]; works directly<br>with token streams|
|**Strengths**|– Understanding meaning – Classification, QA,<br>NER – Contextual embeddings used in many<br>downstream tasks|– Generating coherent long texts – Creative<br>writing – Conversational AI|
|**Weaknesses**|– Cannot generate text beyond input<br>– Limited to understanding|– Weaker in fine-grained text understanding<br>compared to BERT for NLU tasks|



--- end of page.page_number=26 ---

## **Block Diagram of GPT and BERT** 

**==> picture [332 x 346] intentionally omitted <==**

**==> picture [341 x 346] intentionally omitted <==**

--- end of page.page_number=27 ---

## **T5 (Text-to-Text Transfer Transformer)** 

• T5 is a Large Language Model introduced by Google Research in 2019. Unlike models trained for specific tasks (like translation, summarization, or sentiment analysis), T5 reformulates every NLP task as a text-to-text problem. 

- •T5 does everything as text-to-text (encoder–decoder). It inherits the best of both worlds: 

1. A bidirectional encoder for deep input understanding (like BERT), 

2. A generative decoder capable of producing fluent text (like GPT). 

• Input: Always a text string (with a task prefix). 

- Output: Always a text string. 

• Based on the Transformer encoder–decoder structure. Pretrained on a massive dataset called C4 (Colossal Clean Crawled Corpus). 

• Varient - T5-Small, T5-Base, T5-Large, T5-3B, T5-11B (Different parameter scales (60M to 11B). 

- **Examples:** 

1.Translation: _translate English to German: The house is wonderful.”_ → _“Das Haus ist wunderbar.”_ 2.Summarization: _summarize: The movie was long but exciting …”_ → _“Exciting long movie.”_ 3.Question answering: _question: Who discovered gravity? context: Newton was a physicist …”_ → _“Isaac Newton_ 

## • **T5** 

- ✅ Flexible (handles any text task). 

- ✅ Encoder–Decoder good for both understanding & 

- generation. 

- ❌ Slower (full encoder-decoder passes). 

- **BERT** 

- ✅ Strong at understanding (classification, 

embeddings). 

- ✅ Efficient encoder. 

- ❌ Cannot generate free text (only understands). 

- **ChatGPT** 

- ✅ Natural conversations, creative text generation. 

- ✅ RLHF alignment with human preferences. 

- ❌ Prone to hallucinations (makes up facts). 

- ❌ Requires huge compute resources. 

•Many systems combine these models: using BERT for classification or retrieval, then GPT or T5 to generate final outputs. 

--- end of page.page_number=28 ---

## **Block Diagram of T5** 

**==> picture [594 x 292] intentionally omitted <==**

- **Real-World Applications of T5:** 

1. Chatbots and Conversational AI: T5 can generate human-like responses for virtual assistants. 

2. Text Summarization: Used by news aggregators and research tools to summarize articles. 

3. Language Translation: Provides high-quality translations between multiple languages. 

4. Question Answering: Helps build intelligent Q&A systems. 

--- end of page.page_number=29 ---

## **Reinforcement Learning** 

**Reinforcement Learning (RL)** is a branch of machine learning that focuses on how agents can learn to make decisions through trial and error to maximize cumulative rewards. RL allows machines to learn by interacting with an environment and receiving feedback based on their actions. This feedback comes in the form of **rewards or penalties.** 

• In RL: 

- An agent interacts with an environment. 

- The agent receives states, takes actions, and gets rewards (feedback). 

- The goal is to learn a policy that maximizes long-term rewards. 

**==> picture [353 x 197] intentionally omitted <==**

• Unlike supervised learning, you don’t get the “right answer” for each step — instead, you explore and learn from trial and error. Example: 

1. Training a robot to walk →It tries different movements, sees which keep it upright, and improves. 

2. Playing chess →The agent learns strategies through wins/losses, not labeled datasets. 

RL is suitable for solving complex problems and can Handle Non-Deterministic Environments, However it requires high computational power. 

- **Agent** : The decision-maker that performs actions. 

- **Environment** : The world or system in which the agent operates. 

Reinforcement Learning revolves around the idea that an agent (the learner or decisionmaker) interacts with an environment to achieve a goal. The agent performs actions and receives feedback to optimize its decision-making over time. 

- **State** : The situation or condition the agent is currently in. 

- **Action** : The possible moves or decisions the agent can make. 

- **Reward** : The feedback or result from the environment based on the agent’s action. 

--- end of page.page_number=30 ---

## • **Types of Reinforcements in RL** 

## **1. Positive Reinforcement** 

Positive Reinforcement is defined as when an event, occurs due to a particular behavior, increases the strength and the frequency of the behavior. In other words, it has a positive effect on behavior. 

- **Advantages** : Maximizes performance, helps sustain change over time. 

- **Disadvantages** : Overuse can lead to excess states that may reduce effectiveness. 

## **2. Negative Reinforcement** 

Negative Reinforcement is defined as strengthening of behavior because a negative condition is stopped or avoided. 

- **Advantages** : Increases behavior frequency, ensures a minimum performance standard. 

- **Disadvantages** : It may only encourage just enough action to avoid penalties. 

- **Examples & Applications:** 

1. AlphaGo - AlphaGo is an artificial intelligence program developed by DeepMind that combines deep neural networks and reinforcement learning with Monte Carlo Tree Search to play the complex board game Go at superhuman level. 

## 2. Robotics 

## • **Algorithms:** 

   - Q-learning 

   - DQN (Deep Q-Network) 

   - PPO (Proximal Policy Optimization) 

- **Trends:** 

RLHF (Reinforcement Learning with Human Feedback), is Supervised Learning + Human Ranking + Reinforcement Learning, making AI not just smart, but also aligned with what humans want. **Pretraining → Supervised Fine-Tuning (SFT)→Reward Model →RL (PPO) →Final Aligned Model** 

- **Example - Imagine teaching a child to write essays.** 

1. First, they read many books →pretraining. 

2. You give them examples of good essays → SFT. 

3. You read their multiple essays and rank them →reward model. 

4. They practice writing essays, and you give scores →RL. _(PPO is the engine that finetunes the model using the reward model, ensuring it learns human-preferred behavior without drifting too much.)_ 

5. Eventually, they learn to write essays the way you like →aligned model. 

--- end of page.page_number=31 ---

## **Evolutionary Learning (EL)** 

- **EL is a family of optimization and machine learning techniques inspired by biological evolution.** 

-Instead of learning with gradient descent (like deep learning), it evolves a population of candidate solutions using selection, mutation, and recombination — similar to Darwin’s “survival of the fittest. 

•Population →Set of candidate solutions (analogous to species). •Fitness Function →How good a solution is (analogous to survival ability). 

•Selection → Favor the best solutions (natural selection). 

•Crossover / Recombination →Combine 

traits of two parents. 

•Mutation →Introduce random changes to 

explore new possibilities. 

•Generations →Iteratively repeat until good 

solutions emerge. 

• **Advantages:** Good for black-box optimization 

- **Limitations:** 

   - Slow convergence 

- **Examples & Applications:** 

   - Neural architecture search 

- **Evolutionary Algorithms:** 

1. Genetic Algorithms (GA) 

Candidate solutions represented as chromosomes. Uses 

crossover + mutation to evolve better solutions. 

2. Evolution Strategies (ES) 

Focuses more on mutation and step-size adaptation. 

3. Genetic Programming (GP) 

Evolves entire computer programs (tree structures). 

4. Differential Evolution (DE) 

Uses vector differences to guide mutation. 

5. Swarm Intelligence (related) 

Inspired by behavior of ants, birds, fish. Includes PSO (Particle Swarm Optimization), ACO (Ant Colony Optimization), GWO (Grey Wolf Optimizer. • **Trends:** 

-Neuro-Evolution for deep RL (Evolving neural networks 

with survival of the fittest, instead of teaching them with equations.). Neuro-Evolution of Augmenting Topologies 

(NEAT) is an evolutionary algorithm. 

--- end of page.page_number=32 ---

## **Neuro-Evolution** 

- **Neuro-Evolution** is a subfield of Evolutionary Learning where neural networks (weights, architectures, or hyperparameters) are optimized using evolutionary algorithms instead of gradient-based methods like backpropagation. 

- **Advantages:** 

- ✅ No gradients required (works in non- 

- differentiable environments). 

- ✅ Good for **reinforcement learning** where 

rewards are sparse. 

   - ✅ Naturally explores diverse solutions 

- Networks are evolved by selection, mutation, and crossover in a population of candidate network. 

   - **Limitations:** 

   - ❌ Computationally expensive (needs large populations). 

- **Algorithm Flow** 

   - ❌ Slower compared to gradient descent in simple tasks. 

1. Initialize a population of neural networks (random weights/architectures). 

   - ❌ Harder to scale for very deep architecture 

2. Evaluate fitness (performance in environment). 

3. Select the best networks. 

- to create new 

- 4. Apply crossover/mutation offspring networks. 

   - **Famous Neuroevolution Algorithms** 

   - 1. NEAT → NeuroEvolution of Augmenting Topologies. 

5. Repeat →networks improve over generations. • **Variants:** 

   2. CoDeepNEAT → Extends NEAT for deep networks. 

1. Weight Evolution: Only weights are evolved. 

2. Topology Evolution: Both weights and architectures evolve (e.g., NEAT). 

   3. EvoNAS → Evolutionary Neural Architecture Search. 

3. Hybrid Evolution: Combination of gradient descent + evolution 

4. ES (Evolution Strategies) → Used by OpenAI for reinforcement learning 

--- end of page.page_number=33 ---

## **NEAT = NeuroEvolution of Augmenting Topologies.** 

- **Start simple** →begins with very small neural 

- networks. 

- **Mutate gradually** →adds neurons or connections 

- step by step. 

- **Keep innovations** →remembers and protects new 

- useful structures. 

• **Speciation** →networks are grouped like “species” so weaker ones aren’t immediately destroyed, giving new ideas time to improve. 

- **Survival of the fittest** →the best networks (those 

- that solve the task better) survive and reproduce. 

**NEAT evolves both the “brain” (neural network weights) and the “shape of the brain” (topology) over time** . 

**CoDeepNEAT = Cooperative Deep NEAT.** 

It is an extension of NEAT made for evolving deep neural networks (DNNs) automatically. 

While NEAT evolves both the structure and weights of small networks, CoDeepNEAT scales this idea to large, deep architectures. 

## **EvoNAS = Evolution-guided Neural Architecture Search** 

Using evolutionary algorithms to automatically search and optimize neural network architectures instead of designing them by hand. 

**How EvoNAS Works:** 

1. Population Initialization (Start with a set of random neural architectures (like chromosomes in GA). 

2. Evaluation (Train each architecture (partially or fully) on data. Compute its “fitness” (e.g., accuracy, loss, FLOPs, latency)) 

3. Selection (Choose the betterperforming architectures (survival of the fittest). 

4. Variation (Apply mutation (randomly change layers, filter size, skip crossover 

connections). Apply (combine parts of two architectures)) 

5. Iteration (Repeat evaluation + selection + variation until a good architecture evolves) 

--- end of page.page_number=34 ---

## **Evolution Strategies (ES)** 

Evolution Strategies (ES) are a family of black-box optimization algorithms inspired by natural evolution. They don’t need gradients of the objective function — instead, they use random variations and selection to evolve good solutions. 

**How ES Works (Core Steps)** 

1. Initialization - Start with a population of candidate solutions (vectors of parameters). 

2. Mutation (Variation) - Create new candidate solutions by adding random noise (Gaussian perturbations) to existing ones. 

3. Evaluation (Fitness) 

   - Compute the fitness (objective score) of each candidate. 

   - Example: accuracy of a neural network, or reward in reinforcement learning. 

4. Selection (Survival of the fittest) - Pick the best-performing candidates. 

5. Recombination / Update - Combine or update parameters of the best candidates to 

   - form the next generation. 

6. Repeat - Continue until convergence or max generations reached 

**Difference from Genetic Algorithms (GA)** 

- GA: uses crossover + mutation. 

- ES: relies mainly on mutation + step-size adaptation (less on crossover) 

--- end of page.page_number=35 ---

||**ALGORITHM**<br>**What is Evolved?**<br>**How New**<br>**Solutions are**<br>**Created?**<br>**Special Focus**<br>**Simple Analogy**<br>**Genetic**<br>**Algorithms (GA)**<br>Candidate<br>solutions as DNA-<br>like strings<br>Parents crossover<br>(swap parts) +<br>small random<br>mutations<br>Balance of<br>crossover +<br>mutation<br>Like breeding<br>plants/animals to<br>get stronger<br>offspring<br>**Evolution**<br>**Strategies (ES)**<br>Candidate<br>solutions as<br>vectors of<br>numbers<br>Mainly<br>mutations, with<br>clever control of<br>step size (how big<br>a change)<br>Self-adapting<br>mutation<br>strength<br>Like a sculptor,<br>deciding how<br>hard or soft to<br>strike the chisel<br>**Genetic**<br>**Programming**<br>**(GP)**<br>Whole computer<br>programs (tree<br>structures)<br>Parts of two<br>programs<br>swapped + small<br>edits (mutations)<br>Evolving<br>logic/structure,<br>not just numbers<br>Like evolving<br>recipes –<br>changing entire<br>cooking<br>procedures<br>**Differential**<br>**Evolution (DE)**<br>Solutions as<br>vectors (lists of<br>numbers)<br>Uses differences<br>between<br>solutions to guide<br>mutations<br>Exploits<br>directional hints<br>from population<br>Like friends on a<br>map, using the<br>gap between two<br>to guide<br>another’s move|
|---|---|



--- end of page.page_number=36 ---

## **Deep Learning (DL)** 

- DL is a subfield of Machine Learning that uses artificial neural networks with multiple hidden layers to learn hierarchical data representations. 

   - **Key Characteristics:** 

   - Automatic feature learning 

   - • **Advantages:** 

- It automatically extracts features from raw data and solves complex tasks such as image recognition, natural language processing, and speech understanding by minimizing error through backpropagation and optimization algorithms. 

      - High accuracy 

      - Handles unstructured data 

   - **Limitations:** 

      - Black-box nature 

   - Needs large datasets 

   - • **Examples & Applications:** 

- **Key Components of Deep Learning** 

   - Image recognition 

   - • NLP (ChatGPT) 

1. Input Layer – Receives raw data (images, text, audio). 

   - **Algorithms:** 

2. Hidden Layers – Multiple layers that extract hierarchical features: 

   - CNNs (Convolutional Neural Networks): 

   - RNNs (Recurrent Neural Networks) 

   - • Transformers 

- Early layers →simple patterns (edges, shapes, words). 

- Deeper layers →complex structures (faces, objects, sentences). 

   - **Trends:** 

      - **LLMs** - is an advanced deep learning model trained on massive text datasets that can understand, generate, and reason with human language for tasks like answering questions, summarizing, and translation. 

3. Activation Functions – Provide non-linearity (ReLU, Sigmoid, Tanh, GELU). 

4. Output Layer – Produces predictions (e.g., class label, probability). 

   - **Foundation models** - are large, pretrained AI models that serve as a general base (“foundation”) which can be adapted to many downstream applications. 

5. Loss Function – Measures error (Cross-Entropy, MSE (Mean Square Error)). 

6. Optimizer – Updates weights to reduce loss (SGD (Stochastic Gradient Descent), Adam) 

--- end of page.page_number=37 ---

## **Deep Reinforcement Learning (DRL)** 

• **STEPS:** 

**Deep Reinforcement Learning (DRL)** is the crucial fusion of two powerful artificial intelligence fields: deep neural networks and reinforcement learning. 

**1. Initialization:** Construct an agent and set up the issue. 

**2. Interaction** : The agent interacts with its surroundings through acting, which results in states and rewards. 

## **1. Agent & Environment** 

1. Agent = learner (robot, game player). 

   **3. Learning** : The agent keeps track of its experiences and updates its method for making decisions. 

2. Environment = world where it acts 

   **4. Policy Update** : Based on data, algorithms modify the agent's approach. 

   **5. Exploration-Exploitation** : The agent strikes a balance between using well-known actions and trying out new ones. 

- (game, simulation, real world). 

## **2. Interaction** 

1. Agent sees a **state** (e.g., screen pixels). 

2. Chooses an **action** (move left, jump, etc.). 

   **6. Reward Maximization** : The agent learns to select activities that will yield the greatest possible total rewards. 

3. Gets a **reward** (+1, -1, etc.). 

4. Environment gives new **state** . 

      **7. Convergence** : The agent's policy becomes better and stays the same over time. 

**3. Learning with Neural Networks** 

   1. Instead of storing huge tables of Q- values (like classic RL), 

   **8. Extrapolation** : Skilled agents can use what they've learned in fresh circumstances. 

2. The agent uses a **deep neural network** to approximate the best action for each state. 

**9. Evaluation** : Unknown surroundings are used to assess the agent's performance. 

- **10.Use** of the trained agent in practical situations. 

--- end of page.page_number=38 ---

## **Core Components of Deep Reinforcement Learning (DRL)** 

**1. Agent** : The decision-maker or learner who engages with the environment. The agent acts in accordance with its policy and gains experience over time to improve its ability to make decisions. 

**2. Environment** : The system outside of the agent that it communicates with. Based on the actions the agent does, it gives the agent feedback in the form of incentives or punishments. 

**3. State** : A depiction of the current circumstance or environmental state at a certain moment. The agent chooses its activities and makes decisions based on the state. 

**4. Action** : A choice the agent makes that causes a change in the state of the system. The policy of the agent guides the selection of actions. Reward: A scalar feedback signal from the environment that shows whether an agent's behavior in a specific state is desirable. The agent is guided by rewards to learn positive behavior. 

**5. Policy** : A plan that directs the agent's decision-making by mapping states to actions. Finding an ideal policy that maximizes cumulative rewards is the objective. 

--- end of page.page_number=39 ---

**6. Value Function** : This function calculates the anticipated cumulative reward an agent can obtain from a specific state while adhering to a specific policy. It is beneficial in assessing and contrasting states and policies. 

**7. Model** : A depiction of the dynamics of the environment that enables the agent to simulate potential results of actions and states. Models are useful for planning and forecasting. 

**8. Exploration-Exploitation Strategy** : A method of making decisions that strikes a balance between exploring new actions to learn more and exploiting well-known acts to reap immediate benefits (exploitation). 

**9. Learning Algorithm:** The process by which the agent modifies its value function or policy in response to experiences gained from interacting with the environment. Learning in DRL is fueled by a variety of algorithms, including Q-learning, policy gradient, and actor-critic. 

**10. Deep Neural Networks:** DRL can handle high-dimensional state and action spaces by acting as function approximators in deep neural networks. They pick up intricate input-to-output mappings. 

**11. Experience Replay:** A method that randomly selects from stored prior experiences 

(state, action, reward, and next state) during training. As a result, learning stability is improved and the association between subsequent events is decreased. 

--- end of page.page_number=40 ---

|**Aspect**|**Deep Reinforcement Learning (Deep RL)**|**Large Language Models(LLMs)**|
|---|---|---|
|**Definition**|A branch of machine learning that combines<br>reinforcement learning (agents maximizing<br>reward) with deep neural networks for handling<br>complex, high-dimensional states.|Large-scale neural networks (Transformers) trained<br>on massive text corpora to understand and generate<br>natural language.|
|**Primary**<br>**Domain**|Decision-making, control, robotics, games.|Language understanding, generation, reasoning, and<br>conversation.|
|**Training**<br>**Signal**|Reward signals (delayed, sparse, environment-<br>driven).|Next-word prediction / masked token prediction<br>(dense supervision from text corpora).|
|**Learning**<br>**Style**|Trial-and-error exploration in an interactive<br>environment.|Self-supervised learning from static datasets of text.|
|**Architecture**|Deep neural networks (CNNs, RNNs,<br>Transformers) mapping states → actions/value<br>functions.|Transformer-based (encoder-only, decoder-only, or<br>encoder–decoder).|
|**Objective**|Maximize cumulative reward over time (long-term<br>performance).|<br>Minimize prediction loss → generate coherent and<br>meaningful text.|
|**Data**<br>**Requirement**|Needs simulated or real environments for<br>interaction(e.g., games, robotics simulators).|Needs massive text corpora (internet-scale datasets).|
|**Famous**<br>**Examples**|AlphaGo, AlphaZero, DQN, PPO, MuZero, OpenAI<br>Five, robot locomotion agents.|BERT, T5, GPT-3/4/5, ChatGPT, LLaMA, PaLM, Mistral.|
|**Evaluation**|Measured by reward achieved / performance in<br>tasks(e.g., win rate in Go, robot success rate).|Measured by perplexity, BLEU, GLUE/SuperGLUE<br>scores, human eval(e.g., helpfulness, accuracy).|
|**Adaptability**|Can adapt to new environments via exploration.|Can adapt to new tasks via fine-tuning, prompting, or<br>in-context learning.|
|**Strengths**|Excels in sequential decision-making, control,<br>robotics, game-playing.|Excels in language fluency, generalization across NLP<br>tasks, reasoning abilities.|
|**Limitations**|Computationally expensive, unstable training,<br>sparse rewards, requires simulators.|Prone to hallucinations, bias in training data, requires<br>huge compute and data.|



--- end of page.page_number=41 ---

## **Batch Learning (Offline Learning)** 

- **Definition: Learns from entire dataset** 

**at once.** 

- **Key Characteristics:** 

   - Static training 

- **Advantages:** 

   - Stable convergence 

- **Limitations:** 

   - Not adaptive to new data 

- **Examples & Applications:** 

   - Traditional ML pipelines 

- **Algorithms:** 

   - Batch Gradient Descent 

- **Trends:** 

Batch pretraining + fine-tuning = 

- 

(Train on big general data first → then 

specialize for a smaller, specific task) 

## • **Algorithms:** 

## **1. Batch Gradient Descent** 

Updates weights after processing the 

## entire dataset. 

**2. Support Vector Machines (SVM)** 

## (traditional) 

Needs full dataset to compute margins. 

**3. Decision Trees (CART, ID3, C4.5)** 

## Built from a full dataset. 

**4. Random Forests** 

Ensemble of trees trained on the whole dataset. 

**5. k-Nearest Neighbors (k-NN)** 

## Requires full dataset stored for 

## predictions. 

**6. Naïve Bayes** 

## Trained on full dataset statistics. 

**7. Traditional Neural Networks** 

## **(Feedforward, CNN, RNN)** 

Typically trained in batch mode on full dataset. 

--- end of page.page_number=42 ---

## **ID3 — Iterative Dichotomiser 3** 

- Iterative →The algorithm works in an iterative manner, splitting the dataset step by step. 

- Dichotomiser →At each step, it tries to **divide (dichotomize)** the data into subsets. 

- 3 →It was the **third version** designed by Ross Quinlan. 

- Hence, **ID3** = the 3rd version of an algorithm that splits data iteratively 

- **C4.5 — Classifier version 4.5** 

- _C_ = Classifier (it was a classificationfocused improvement over ID3). 

- • _4.5_ = It was the **4.5th release** in Quinlan’s series of algorithms. 

Hence, **C4.5** = Quinlan’s classifier, version 4.5 

**CART — Classification and Regression Trees** 

- Unlike ID3 and C4.5 (which were mainly for classification), CART was designed to handle the supervised ML techniques like **classification and** . 

- **regression tasks** 

- It can output either a **classification tree** or a (categorical labels) 

- **regression tree** (numeric predictions). 

- Hence, **CART** = Decision trees that can work for **both classification and regression** 

--- end of page.page_number=43 ---

## **Online Learning** 

## • **Definition: Incremental learning as new data arrives.** 

- **Key Characteristics:** 

   - Real-time updates 

- **Examples & Applications:** 

   - Stock price prediction 

   - Recommendation systems 

- **Advantages:** 

   - Handles streaming data 

- **Limitations:** 

   - Hard to revisit past data 

- **Trends:** 

   - Continual online learning (online learning that never stops, keeps adapting, and never forgets 

      - past knowledge.) 

- **(Normal Offline learning-** train once; 

- **Online Learning-** continuous but forgetful; 

**Continual Online Learning-** continuous + memory 

retention) 

- **Algorithms can also be modeled in online mode:** 

1. Online Gradient Descent 2. Stochastic Gradient Descent 

   - (SGD) 

3. Incremental Support Vector Machines (Online SVMs) 

4. Perceptron Algorithm (Online Version) 

5. Reinforcement Learning algorithms 

6. Online k-means 7. Hoeffding Trees (Very Fast Decision Trees, VFDT) 

--- end of page.page_number=44 ---

## **Very Fast Decision Tree (VFDT)** 

- VFDT is an algorithm to build decision trees on streaming data (data arriving continuously like Weather Sensor Network, Mobile Sensor 

**Example** 

Suppose we are comparing two features for splitting: 

Data etc) 

• Feature A (info gain = 0.45) 

- Traditional decision trees need all the data before training, but VFDT can learn incrementally — it updates the tree as new data arrives. 

• Feature B (info gain = 0.40) 

• Difference = 0.05 

Now, compute **ε** using the Hoeffding Bound: • If ε = 0.02, then 0.05 > 0.02 →We are confident A is better → **split with A** . • If ε = 0.08, then 0.05 < 0.08 →We don’t have enough evidence yet → **wait for more data** 

- It is fast and memory-efficient, so it works well for big data streams. 

- Hoeffding Bound is a mathematical guarantee used in VFDT. It says “If you’ve seen enough samples, you can be almost sure which feature is best for splitting — without needing the full dataset” 

•VFDT is best for real-time, high-speed, large-scale data. •Domains: Finance, IoT, Healthcare, Security, Ads, Games, Weather, Transport •Advantage: incremental learning, low memory, mathematically guaranteed split (Hoeffding Bound ) 

- The Hoeffding Bound is: 

**==> picture [115 x 47] intentionally omitted <==**

- Where: 

1. ε (epsilon) → the “margin of error.” 

2. R → the range of the variable (e.g., 

   - information gain is always between 0 and 1, 

so R = 1). 

3. δ (delta) → the confidence parameter (like 0.05 → 95% confidence). 

4. n → number of samples observed 

--- end of page.page_number=45 ---

||**Aspect**<br>**Traditional Decision Tree (Batch Learning)**<br>**Very Fast Decision Tree (VFDT – Streaming**<br>**Learning)**<br>Data Input<br>Needs the entire dataset beforehand<br>Works with data streams (arriving one by one)<br>Training Style Batch learning – tree built once using full dataIncremental learning – tree updated as new data<br>arrives<br>Memory<br>Requirement<br>Stores and processes the whole dataset in<br>memory<br>Stores only statistics (counts, info gains), not raw data<br>Splitting<br>Decision<br>Chooses the best feature after scanning all dataUses Hoeffding Bound to decide when enough data is<br>seen for a confident split<br>Update<br>Model is fixed after training → must retrain<br>with new data<br>Model grows continuously → adapts to new data<br>Use Cases<br>Small to medium datasets (offline learning)<br>Large-scale or infinite data streams (online ads,<br>sensors, transactions)<br>Speed<br>Slower if dataset is very large<br>Very fast, designed for high-speed streams<br>Guarantee<br>Exact best split found with all data<br>Probabilistic guarantee (confidence from Hoeffding<br>bound)|
|---|---|



--- end of page.page_number=46 ---

||**ASPECT**<br>**ONLINE LEARNING**<br>**OFFLINE LEARNING**<br>**Definition**<br>Model learns continuously as new data<br>arrives, updating itsparameters in real-time.<br>Model is trained once on a fixed dataset<br>before deployment.<br>**Data Input**<br>Data is processed one sample (or small mini-<br>batches) at a time(streaming).<br>Requires the complete dataset<br>beforehand.<br>**Storage Requirement**<br>Does not need to store all past data, only<br>current sample/batch.<br>Needs large storage to hold the entire<br>dataset.<br>**Computation**<br>Light and incremental; updates happen<br>continuously.<br>Heavy computation upfront during<br>training.<br>**Adaptability**<br>Quickly adapts to new data and changing<br>environments.<br>Not adaptive; must retrain from scratch<br>when new data comes.<br>**Stability**<br>Can be unstable due to noisy updates, needs<br>regularization.<br>More stable since trained on full<br>dataset.<br>**Speed of Updates**<br>Fast updates after each new sample.<br>Slow updates; requires full retraining.<br>**Performance**<br>May fluctuate with noise, but good for<br>dynamic environments.<br>Stable, high accuracy in static<br>environments.<br>**Use Cases**<br>Stock price prediction, recommendation<br>systems, online fraud detection, self-driving<br>cars.<br>Image classification, speech<br>recognition, spam filtering.<br>**When to Use**<br>When data arrives in streams, or when<br>patterns change over time.<br>When data is static, large, and collected<br>before training.<br>**Analogy**<br>Learning a language by daily conversations<br>(adapting on the fly).<br>Learning a language through a full<br>course before speaking.<br>**Examples of Algorithms** Online gradient descent, Incremental SVM,<br>Reinforcement Learning agents.<br>Batch gradient descent, traditional<br>supervised learning (SVM, Random<br>Forest).|
|---|---|



--- end of page.page_number=47 ---

## **Curriculum Learning (CL)** 

- Curriculum Learning is a training strategy where the model is taught in a structured way — starting from easier tasks/data and gradually moving to harder ones, just like how humans learn. 

- Instead of showing all training data randomly, we order it by difficulty level. 

- • Curriculum Learning = “teaching machines like humans” — start simple, then increase difficulty 

- Curriculum Learning is not a separate type of ML like supervised or unsupervised, but rather a training strategy that can be applied on top of them. **Curriculum Learning is a meta-strategy** — it decides _how_ to feed data/tasks to the model, but the model itself can be supervised, unsupervised, or RL. 

- **STEPS:** 

1. Define difficulty measure – Decide what makes a sample “easy” or “hard.” (e.g., in image classification: clearer images = easy, noisy/occluded images = hard) 

2. Organize data – Split training data into levels (easy →medium →hard). 

3. Train gradually – Start with easy samples, then expand training to harder samples. 

4. Refine – By the time model sees the hardest cases, it has already built strong foundations 

--- end of page.page_number=48 ---

• **Benefits** 

**1. Faster Convergence** – models often reach good accuracy in fewer training steps. 

**2. Better Generalization** – learns patterns that transfer well to unseen, complex data. 

**3. Training Stability** – avoids confusion early on by starting simple. 

**4. Human-like Learning** – mirrors how humans progress from easy →hard. 

**5. Improved Robustness** – can handle noisy/complex data better after staged learning 

- **Limitations** 

**1. Defining “Difficulty” is Hard** – deciding what makes an example _easy_ or _hard_ is not straightforward, and often task-dependent. (e.g., In NLP: is a short sentence always easier than a long one? Not necessarily.) 

**2. Manual Curriculum Design** – requires expert knowledge or heuristics to create the sequence (time-consuming). 

**3. Risk of Oversimplification** – if the curriculum is too simple for too long, the model might underfit or fail to explore harder cases properly. 

**4. Data Bias** – ordering data by difficulty might unintentionally introduce bias, making the model less fair or less balanced. 

**5. Not Always Beneficial** – for some tasks (especially if data is already balanced and homogeneous), curriculum learning gives little or no advantage. 

**6. Computational Overhead** – implementing staged training adds complexity compared to random shuffling of data. 

--- end of page.page_number=49 ---

- **Where Curriculum Learning Fits:** 

**1. Supervised Learning -** Order the labeled data from easy →hard. (Example: Train an image classifier first on clear, centered digits →then on rotated, noisy digits.) 

**2. Unsupervised Learning-** Order the unlabeled data based on a notion of difficulty 

   - (e.g., cluster “well-separated” points first, then messy ones). 

**3. Reinforcement Learning (RL)-** Known as **“Progressive Tasks”** or **“Curriculum RL.”** (Example: A robot learns to walk on flat ground first, then on slopes, then on stairs) 

- **Algorithms Using Curriculum Learning:** 

1. Task scheduling is a direct form of curriculum learning. It decides which tasks, when, and how much, shaping the curriculum automatically or manually. 

2. Classical CL algorithms: SPL, SPCL, Competence-based CL. 

3. RL algorithms: GoalGAN (Goal Generative Adversarial Network); ALP-GMM (Automatic Learning Progress – Gaussian Mixture Model), ADR (Automatic Domain Randomization), PAIRED (Protagonist-Antagonist Induced Regret Environment Design) 

4. NLP/LLMs: Baby Steps curriculum, Length-based curricula, Instruction curriculum, Noise/Mask scheduling 

--- end of page.page_number=50 ---

## **Transfer Learning (TL)** 

Transfer Learning is a machine learning technique where a model trained on one task/domain is reused (partly or fully) for another related task. Instead of starting from scratch, we transfer the knowledge from one setting to another. 

**“Don’t start from zero. Stand on the shoulders of a pretrained model, and adapt it to your own task.”** 

**Key Characteristics:** Knowledge reuse 

**Approaches to Transfer Learning 1.Feature Extraction** 

- Use the learned features of a pre-trained model as input to a new classifier. 

- Example: Freeze CNN layers and only train the final fully connected layer. 

## **2. Fine-Tuning** 

- Start with a pre-trained model and continue training it on new data. 

- Example: Unfreeze some deeper layers and adjust weights for the target task. 

## **3. Domain Adaptation** 

- Adjusting models trained on one domain (e.g., 

- daytime images) to perform well in another (e.g., nighttime images) 

   - one domain (e.g., 

## **Advantages:** 

- Saves compute and data 

**Limitations:** 

- Risk of negative transfer 

**Examples & Applications:** 

   - Fine-tuning BERT (Bidirectional Encoder Representations from Transformers) 

   - ImageNet pre-trained CNNs 

- **Algorithms:** 

   - Domain adaptation 

   - Parameter transfer 

   - Feature Transfer 

**Trends:** 

- Few-shot and zero-shot learning 

**==> picture [309 x 184] intentionally omitted <==**

--- end of page.page_number=51 ---

## **Domain Adaptation** 

- Domain adaptation is a type of transfer learning where the source task and target task are the same, but the data distributions differ. 

- **Example** : 

   1. A **spam detection** model trained on English emails (source domain) adapted for Hindi or Hinglish emails (target domain). 

   2. An object detection model trained on **daytime images** adapted to work on **nighttime images** . 

   **3. Vision** : Daytime →Nighttime self-driving car vision. 

   **4. Text** : Sentiment analysis model trained on movie reviews →adapted to product reviews. 

   **5. Speech** : Speech recognition trained on American English →adapted to Indian English 

- **Goal:** Reduce the mismatch between source domain (where we have lots of labeled data) and target domain (where labeled data is limited). 

- **Techniques** : 

1. Feature alignment (making source & target feature distributions similar). 

2. Adversarial training (like GAN-based domain adaptation). 

3. Fine-tuning with few target samples 

- **Advantages** 

1. Useful when labeling target domain is costly. 

2. Critical in real-world applications (medical, autonomous driving, speech). 

- **Limitations** 

1. If domains differ too much (e.g., photos →sketches), adaptation may fail. 

2. Needs careful domain similarity checks 

--- end of page.page_number=52 ---

## **Parameter Transfer** 

   - **Example** : 

- Parameter transfer refers to reusing the learned parameters/weights (like filters in CNNs or embeddings in Transformers) from a source model to initialize or constrain the target model. 

- • **Idea** : Since parameters encode prior knowledge, transferring them helps the target task converge faster and better. 

   1. Using ImageNet-pretrained CNN weights for medical X-ray classification. 

   2. Using BERT embeddings for sentiment analysis. 

   3. Fine-tuning BERT for question answering (SQuAD). 

   4. Fine-tuning ResNet on medical imaging. 

   5. Using GPT for summarization after pretraining on general web data. 

- Suppose you already know how to play acoustic guitar and now you’re learning electric guitar. 

   - **Advantages** 

   - 1. Retains general knowledge while adapting to target. 

**1. Freezing parameters** = you don’t relearn chords (keep old knowledge fixed). 

**2. Regularization constraint** = while adjusting to electric, you try to stay close to your acoustic style so you don’t lose it. 

   2. Often leads to state-of-the-art performance in vision and NLP. 

   3. Can handle moderately different tasks (e.g., classification →detection). 

**3. Full fine-tuning** = you allow yourself to change completely if needed. 

- **Methods** : 

**1. Direct reuse** – freeze layers and only train last layers. 

**2. Fine-tuning** – unfreeze some or all parameters and retrain on target task. 

**3. Regularization-based transfer** – constrain target parameters to stay close to source parameters. 

- **Limitations** 

1. Computationally more expensive than feature transfer. 

2. Risk of catastrophic forgetting (losing source knowledge). 

3. Requires careful tuning of learning rate and frozen/unfrozen layers 

--- end of page.page_number=53 ---

## **Feature Transfer** 

   - **Advantages** 

- **Feature Transfer** is a type of transfer learning where the features (patterns, representations, or embeddings) learned by a model trained on one task are reused for another related task. 

   1. Very fast — no need to retrain entire network. 

   2. Effective when target data is very small. 

- Instead of retraining the entire model, we keep the learned features fixed (like edges, shapes, or word meanings) and only train a new classifier or small part of the model for the new task. 

   3. Avoids risk of overfitting, since pre-trained layers remain frozen. 

   - **Limitations** 

- When you buy a camera, the lens already knows how to capture edges, shapes, and colors. You don’t need to build a new lens every time you want to take a photo of a different object. Instead, you reuse the same lens and just change what you focus on (flowers, faces, cars, etc.). 

   1. Might not capture nuances of the new task if domains are very different. 

   2. Works best when source and target domains are related. 

- In the same way, in feature transfer, A pre-trained neural net model has already learned useful patterns (edges in images, meanings of words in text, etc.). We reuse these learned features for a new but related task 

   - **Examples** 

   1. Computer Vision: Use VGG/ResNet CNN trained on ImageNet →extract features →classify new dataset (like flower species or X-rays) with an SVM/MLP. 

- **Examples:** 

- 1.Cooking - Once you know how to chop vegetables, boil water, and fry, you can cook many dishes. You don’t relearn how to chop each time — you reuse that skill. The “features” (chopping, boiling, frying) are transferred, while the final recipe changes. 

   2. NLP: Use embeddings from Word2Vec, GloVe, or BERT →train a shallow model for sentiment analysis or topic classification. 

- 2.Sports - If you play cricket, your hand–eye coordination helps you play badminton. You reuse the basic skill (tracking fastmoving objects). Only rules and equipment differ 

3. Audio: Use pre-trained speech embeddings (Wav2Vec2, HuBERT) → detect speaker emotions 

--- end of page.page_number=54 ---

||**Aspect**<br>**Feature Transfer**<br>**Parameter Transfer**<br>**Domain Adaptation**<br>**What is**<br>**reused?**<br>Feature representations<br>Model weights/parameters<br>Knowledge/generalization ability<br>across domains.<br>**Task relation** Source and target tasks are usually<br>related but not identical.<br>Tasks may be same or related<br>Task remains the same, only the<br>input domain changes.<br>**Domain**<br>**relation**<br>Source and target domains should<br>be similar for features to be useful.<br>Can be same or moderately<br>different.<br>Explicitly handles different<br>distributions(domain shift).<br>**Training**<br>**effort**<br>Very low (train only a shallow<br>classifier on top).<br>Moderate to high (fine-tuning<br>layers).<br>Moderate to high (need special<br>adaptation techniques).<br>**Data**<br>**requirement**<br>Works well with very little target<br>data.<br>Needs at least a small amount<br>of labeled target data.<br>Often needs unlabeled target data<br>+ few labels.<br>**Computation**<br>Light and fast (few parameters<br>trained).<br>Heavier (many parameters<br>updated).<br>Often requires extra models (e.g.,<br>domain discriminator).<br>**Techniques**<br>Use frozen embeddings<br>Fine-tuning, partial layer<br>freezing, regularization-based<br>transfer.<br>Instance re-weighting, feature<br>alignment, adversarial training,<br>self-training.<br>**Advantages**<br>Quick, avoids overfitting, great for<br>small datasets.<br>High accuracy, flexible, captures<br>task-specific nuances.<br>Works even when data<br>distributions differ; very practical<br>in real world.<br>**Limitations**<br>Not effective if source & target are<br>very different.<br>Risk of catastrophic forgetting;<br>needs careful tuning.<br>May fail if domains are too far<br>apart(photos → sketches).<br>**Real-life**<br>**analogy**<br>Using your knowledge of chopping,<br>boiling, frying to cook new dishes.<br>Knowing acoustic guitar chords<br>and fine-tuning to play electric<br>guitar.<br>Playing cricket in India vs.<br>playing cricket in England (same<br>rules, different conditions).<br>**AI Examples**<br>•<br>ImageNet CNN features → SVM<br>for flower classification.<br>•<br>BERT embeddings → sentiment<br>classifier.<br>•<br>Fine-tuning ResNet on<br>medical images.<br>•<br>Fine-tuning GPT/T5 for<br>summarization.<br>•<br>Movie reviews sentiment →<br>product reviews sentiment.<br>•<br>Daytime driving → nighttime<br>driving.|
|---|---|



--- end of page.page_number=55 ---

## **Zero-Shot Learning (ZSL)** 

• The model performs a **task without seeing any labeled examples** of that task during training. It relies on general knowledge and descriptions (semantic transfer). 

- **Example in AI:** 

1. A model trained on general text is asked to do **sentiment analysis** (“Is this review positive or negative?”) without ever being trained specifically on sentiment labels. 

2. Image recognition →classify “zebra” even if it has never seen a zebra image, by using a textual description: “zebra = animal with black and white stripes.” 

• **Real-life Analogy:** You’ve never tasted **sushi** , but someone describes it as “vinegared rice with raw fish.” When you see it for the first time, you recognize it without prior experience 

**==> picture [311 x 253] intentionally omitted <==**

--- end of page.page_number=56 ---

## **Few-Shot Learning (FSL) & One-Shot Learning (OSL)** 

- **FSL model** learns a new task using only a few labeled examples per class (instead of thousands). 

- **Example in AI:** 

1. Image classification →given only 5 labeled cow images and 5 labeled dog images, the model can learn to classify cows vs dogs. 

2. In NLP, fine-tuning GPT with only a few sentiment-labeled reviews. 

- **Real-life Analogy:** Imagine you are shown 3–4 photos of a new fruit (say, dragon fruit). Next time you see it at the market, you can recognize it, even though you didn’t see thousands of pictures 

- **One-Shot Learning (OSL) Is A Special Case Of Few-shot Learning.** 

- Few-Shot Learning →the model learns from a few labeled examples per class (could be 2, 5, 10, etc.). 

- One-Shot Learning →the model learns from exactly one example per class. 

- **So, One-Shot = Few-Shot where “few = 1.** 

**==> picture [324 x 214] intentionally omitted <==**

**==> picture [324 x 214] intentionally omitted <==**

--- end of page.page_number=57 ---

||**Aspect**<br>**Traditional Transfer**<br>**Learning**<br>**Zero-Shot**<br>**Few-Shot**<br>**How transfer**<br>**happens**<br>Fine-tuning model<br>parameters on target<br>data<br>No fine-tuning;<br>model directly<br>applies pretrained<br>knowledge<br>No fine-tuning;<br>model uses a few<br>examples in prompt<br>**Data**<br>**requirement**<br>Needs some labeled<br>data for fine-tuning<br>No labeled data<br>needed<br>Very few labeled<br>examples(2–10)<br>**Adaptation**<br>**mechanism**<br>Weight updates<br>Prompt-based<br>reasoning<br>Prompt-based<br>reasoning with<br>examples<br>**Example**<br>ImageNet-pretrained<br>CNN → fine-tuned for<br>X-ray classification<br>LLM answers<br>questions in a new<br>domain without<br>training<br>LLM classifies<br>sentiment after<br>seeing 3 labeled<br>examples in the<br>prompt|
|---|---|



--- end of page.page_number=58 ---

## **Meta Learning** 

**==> picture [303 x 220] intentionally omitted <==**

## • **Meta Learning is “Learning to learn” – models adapt quickly to new tasks.** 

- **Key Characteristics:** 

   - If a teacher teaches only maths problem, student will be good at maths but stuck if teacher suddenly give him/her history. But if teacher teach how to study any subject (note-making, summarizing, practice tricks), then student can quickly learn math, history, or science — even new subjects. Meta-Learning is like training a student not for one subject, but for the skill of learning any new subject quickly. 

**Trends:** 

      - Meta-learning for AutoML (Automated Machine Learning) - using past learning experiences to guide model and hyperparameter choices for new datasets. 

- **Algorithms:** 

   1. MAML (Model-Agnostic Meta-Learning): An optimization-based meta-learning algorithm that trains models to quickly adapt to new tasks with just a few gradient updates. 

   - This makes AutoML faster, more accurate, and less resource-hungry. Normally, AutoML tries many models (like random search or Bayesian optimization). 

2. Reptile - A simplified meta-learning algorithm similar to MAML that learns initialization parameters by repeatedly sampling tasks and moving the model parameters toward taskspecific solutions. 

- With Meta-Learning, AutoML can reuse prior experience (from similar tasks) to _warm-start_ the search and make better decisions quickly. 

--- end of page.page_number=59 ---

- **Advantages:** It makes AutoML faster, more accurate, data-efficient, and adaptable by providing warm starts for optimization, leveraging prior knowledge across datasets, improving real-world usability, and enabling better performance even on small datasets. 

- **Limitations:** It suffers from negative transfer, dependence on good meta-feature design, storage/complexity issues, bias towards seen tasks, scalability challenges, and still requires some search/exploration. 

- **Examples** 

   1. Auto-sklearn (2015, Germany): Uses meta-learning to recommend algorithms based on dataset metafeatures (e.g., number of samples, features, sparsity). Example: If dataset has many categorical features → suggests tree-based methods instead of linear models. 

   2. Google Vizier / AutoML-Zero: Google integrates meta-learning into its AutoML systems to reuse knowledge from prior optimization runs. 

   3. AutoKeras (Texas A&M + Google): Uses Neural Architecture Search (NAS) with meta-learning to warmstart from architectures that worked on similar datasets. 

   4. HPO-Bench + Meta-Learning: Hyperparameter optimization benchmark where meta-learning is used to warm-start hyperparameter tuning across tasks 

- **Applications** 

   1. Algorithm Recommendation: Predict which ML algorithm is best suited for a new dataset. 

   2. Hyperparameter Optimization (HPO): Start with promising hyperparameter values instead of random guessing. 

   3. Neural Architecture Search (NAS): Reuse knowledge of successful neural network designs across datasets, reducing cost. 

   4. Small Data Learning: When datasets are tiny, meta-learning provides prior knowledge to stabilize 

      - AutoML. 

   5. Industrial AutoML: Cloud platforms (Google Cloud AutoML, Microsoft Azure AutoML) integrate metalearning to make AutoML more efficient and cost-effective 

--- end of page.page_number=60 ---

||**Aspect**<br>**Zero-Shot Learning**<br>**One-Shot Learning**<br>**Few-Shot Learning**<br>**Meta-Learning**<br>**Definition**<br>Perform a new task<br>without any examples,<br>using only prior knowledge<br>and instructions/prompts.<br>Learn a new task with<br>exactly 1 example per<br>class.<br>Learn a new task with a<br>small number of<br>examples per class (e.g.,<br>2–50).<br>Learn how to learn:<br>train on many few-<br>shot tasks to adapt<br>quickly to new ones.<br>**Data**<br>**Requirement**<br>0 examples (just task<br>description or prompt).<br>1 labeled example per<br>class.<br>Few labeled examples<br>per class.<br>Many tasks, each with<br>few examples.<br>**Goal**<br>Generalize to unseen tasks<br>with no training examples.<br>Generalize from a<br>single example.<br>Generalize from a<br>handful of examples.<br>Acquire a strategy to<br>adapt quickly to new<br>tasks.<br>**Difficulty**<br>Hardest (no training<br>samples).<br>Very hard (minimal<br>information).<br>Easier than one-shot<br>(slightly more data).<br>Learns meta-<br>knowledge, so new<br>tasks become easier.<br>**Approach**<br>Relies on pretrained<br>models + instructions.<br>Relies on strong feature<br>extraction and<br>similarity matching.<br>Uses pretrained models<br>fine-tuned on few<br>examples.<br>Uses model-based,<br>metric-based, or<br>optimization-based<br>meta-learning.<br>**Example**<br>Translate English→French<br>without ever seeing French<br>examples (via pretrained<br>LM).<br>Face recognition with 1<br>photo per person.<br>Face recognition with 5<br>photos per person.<br>MAML, Matching<br>Networks,<br>Prototypical Networks<br>→ adapting quickly to<br>a new classification<br>task.|
|---|---|



--- end of page.page_number=61 ---

## **Multi-Task Learning** 

## • **Learning multiple tasks simultaneously with shared representation.** 

**==> picture [327 x 240] intentionally omitted <==**

- saves 

- **Advantages:** Improves generalization, training cost, enables knowledge transfer, and is data-efficient. 

- **Limitations:** Risk of negative transfer, task imbalance, optimization challenges, and difficulty in interpretability. 

- • **Examples & Applications:** Joint NLP tasks; Vision multitask networks 

- • **Algorithms:** 

   - Hard/soft parameter sharing 

|**Aspect**|**Hard Sharing**|**Soft Sharing**|
|---|---|---|
|**Parameter**<br>**Structure**|Shared hidden<br>layers + task-<br>specific heads|Separate models,<br>regularized<br>parameters|
|**Efficiency**|High (fewer<br>parameters)|Low (more<br>parameters)|
|**Best for**|Related tasks|Less-related tasks|
|**Risk**|Negative transfer<br>if tasks are<br>unrelated|Higher compute cost|



**==> picture [327 x 241] intentionally omitted <==**

--- end of page.page_number=62 ---

## **Unified Multitask Transformers (UMT)** 

• Unified Multitask Transformers are advanced architectures designed to handle multiple tasks within a single transformer framework, instead of training separate models for each task. **They extend the principle of Multi-Task Learning (MTL) but leverage the scalability and flexibility of transformers.** 

• Classical MTL: separate tools in one box 

UMT: Like Swiss Army Knife where different tools in one root joint (i.e., one integrated backbone) 

**Major Advantage of UMT: Generalization Across Diverse Tasks** 1.A single backbone handles many tasks (translation, summarization, Q&A, reasoning, etc.). 2.Supports zero-shot and few-shot learning →can perform even on unseen tasks with just instructions. 

3.Enables knowledge transfer between tasks →one model becomes a universal problem solver. 

**Major Limitation of UMT: Compute & Resource Hungry** 1.Training requires **billions of tokens (** Very large datasets) and **massive compute** (hundreds/thousands of GPUs/TPUs), AND **Long training times** (weeks or months). 

• T5 (by Google) was trained on the _Colossal Clean Crawled Corpus (C4)_ with thousands of TPU cores. 

• GPT-3 training consumed thousands of petaflop/s-days of compute — only big labs (OpenAI, Google, DeepMind) can afford it. 

2. Only large organizations can train such models from scratch. 3. Risk of **capacity bottleneck** — when too many tasks compete for the same backbone, performance may degrade. 

**==> picture [371 x 256] intentionally omitted <==**

--- end of page.page_number=63 ---

||**Aspect**<br>**Classical Multi-Task Learning (MTL)**<br>**Unified Multi-Task Transformers (UMT)**<br>**Backbone**<br>Shallow/medium neural nets (CNNs,<br>RNNs, shared layers)<br>Large transformer backbone<br>(encoder–decoder or decoder-only)<br>**Task Format**<br>Tasks handled separately with task-<br>specific heads<br>Tasks unified into a common format (often text-<br>to-text)<br>**Knowledge**<br>**Sharing**<br>Through shared hidden layers<br>Through shared transformer +<br>prompts/adapters<br>**Scalability**<br>Works well for a few closely related<br>tasks<br>Scales to 100s of diverse tasks<br>**Generalization**<br>Improves within related tasks only<br>Strong cross-task generalization, even to unseen<br>tasks(zero/few-shot)<br>**Applications**<br><br>Multi-label image classification<br>(lion, dogs, birds)<br><br>Speech recognition + speaker ID<br><br>Joint medical image diagnosis<br><br>NLP multitask models (T5, mT5, FLAN-T5,<br>GPT)<br><br>Translation, summarization, Q&A, reasoning<br>in one model<br><br>Multimodal tasks (vision-language like PaLI,<br>GPT-4V)<br>**Examples**<br><br>CNN backbone for object detection<br>+ segmentation<br><br>RNN for POS tagging + NER<br>T5, mT5, FLAN-PaLM, GPT-family (instruction-<br>tuned LLMs)<br>**Compute Cost**<br>Relatively low – can be trained on<br>smaller datasets and GPUs<br>Very high – requires billions of tokens, large-<br>scale GPUs/TPUs, weeks of training<br>**Limitations**<br>Negative transfer, task imbalance,<br>complex architecture design<br>Compute hungry, capacity bottleneck, task<br>conflicts|
|---|---|



--- end of page.page_number=64 ---

## **Incremental Learning** 

- Incremental Learning is a technique where a machine learning model learns from data in small chunks or batches rather than all at once. This is useful when working with very large datasets or streaming data that can’t fit into memory. Scikit-learn a popular machine learning library in Python that supports incremental learning using models that implement the partial_fit() method which allows you to train your model on fone batch at a time, update it with new data continuously and avoid retraining from scratch. 

**==> picture [361 x 236] intentionally omitted <==**

- The model keeps learning like a student attending classes every day, without forgetting old lessons.” 

## **Types of Incremental Learning:** 

- **Key Features:** 

– 1.Class-Incremental Learning Model learns new classes over time (e.g., first rabbits vs dogs, later add horses). 

1. Continuous Adaptation: Model updates itself as new data arrives (streaming or sequential). 

2. Knowledge Retention: Should avoid catastrophic forgetting (forgetting old knowledge when learning new). 

3. Resource Efficiency: Learns incrementally → no need to store/retrain on entire old dataset. 

2.Task-Incremental Learning – Model learns new tasks sequentially (e.g., classification first, then detection). 3.Data-Incremental Learning – Model learns from data arriving in chunks or streams (e.g., sensor data updates) 

--- end of page.page_number=65 ---

|**Advantages**|**Limitations**|**Applications**|
|---|---|---|
|Learns continuously without<br>retraining from scratch.|Suffers from catastrophic forgetting<br>if not managed well.|Autonomous Vehicles – adapt to<br>new road/traffic conditions.|
|Efficient in terms of time and<br>resources (no need to store all<br>past data).|Balancing old and new knowledge is<br>difficult.|<br>Healthcare AI – update with new<br>patient records and medical<br>knowledge.|
|Mimics human-like learning<br>(learning over time).|Requires careful memory or<br>rehearsal strategies.|Recommendation Systems –<br>update with new userpreferences.|
|Suitable for real-world dynamic<br>environments.|Model complexity may increase over<br>time.|<br>Fraud Detection – adapt to<br>evolving fraudpatterns.|
|Enables long-term deployment<br>(robots, IoT, edge devices).|Risk of bias if new data overwhelms<br>old data.|<br>Robotics – continuous adaptation<br>in changing environments.|



- Incremental Learning is powerful for real-world, evolving data systems like self-driving cars, healthcare, and fraud detection. But it must overcome catastrophic forgetting and the challenge of balancing old vs new knowledge. 

- **Algorithms:** 

1. EWC (Elastic Weight Consolidation): A continual learning method that prevents catastrophic forgetting by selectively slowing down learning on important parameters for previously learned tasks. 

2. LWF (Learning without Forgetting): A continual learning approach that preserves knowledge of old tasks by distilling outputs of the previous model while training on new tasks. 

- **Trends:** 

   - Continual AI - ability of models to learn new tasks over time while retaining knowledge from past tasks. It is the organization + community supporting research in Continual Learning (CL). 

--- end of page.page_number=66 ---

## **Continual Learning (CL)** 

- Continual Learning (a.k.a. lifelong/never-ending learning) trains a model on a stream of tasks or data so it can learn new things without forgetting what it already knows. 

- It represents a paradigm shift from this conventional approach. Generally, Machine Learning models work over a fixed dataset and do not evolve. It is not the same in LML’s (Lifelong Machine Learning) case, it retains previous knowledge while learning and adapting new information and applying it to new situations. 

- Life-long machine learning (LML) does not have a fixed dataset; it keeps learning, revolutionizing multiple sectors, and making intelligent decisions. This means the system's capability of continuous learning. 

**==> picture [638 x 311] intentionally omitted <==**

--- end of page.page_number=67 ---

## **Hybrid Learning** 

• Hybrid learning refers to combining two or more machine learning paradigms or methods to leverage their strengths and overcome individual limitations. Instead of relying on just one approach (e.g., supervised or unsupervised), hybrid learning integrates multiple strategies. 

- **TYPES OF HYBRID LEARNING:** 

## **1. Supervised + Unsupervised (SemiSupervised Learning)** 

- Uses a small amount of labeled data + a large amount of unlabeled data. 

- Example: Image classification where only 10% of images are labeled, rest are learned with clustering/consistency. 

## **2. Neural + Symbolic (Neuro-Symbolic AI)** 

- Combines deep learning (pattern recognition) with symbolic reasoning (logic, rules). 

- • Example: Visual question answering (detect objects via CNN + reason about them using symbolic logic). 

## **3. Reinforcement Learning + Evolutionary Algorithms** 

- RL learns optimal policies, while evolutionary search explores diverse strategies. 

- Example: Robotics navigation using RL fine-tuning after evolutionary search. 

## **4. Hybrid Classical + Deep ML** 

- Combine traditional ML (SVMs, decision trees) with deep models. 

- Example: Feature extraction with CNN, then classification with an SVM. 

## **5. Hybrid Continual Learning Strategies** 

   - Mix of regularization (EWC, SI) + replay methods + knowledge distillation. 

   - Helps reduce catastrophic forgetting in continual learning. 

- **Advantages:** 

      - Better than individual approaches 

- **Limitations:** 

      - Complex 

- **Examples & Applications:** 

      - Semi-supervised hybrids 

      - • RL + imitation 

- **Algorithms:** 

      - Hybrid deep nets 

- **Trends:** 

      - Hybrid symbolic + neural 

--- end of page.page_number=68 ---

## **Hybrid AI Agents (Best of all worlds)** 

- Real-world problems rarely fit neatly into one method, that’s where hybrid agents shine. These agents combine different architectures (reactive, goalbased, utility-based, learning, etc.) into a cohesive system that can operate flexibly under diverse conditions. 

- Core characteristics: 

**1. Architectural fusion:** Mix multiple agent types to harness the strengths of each. 

**2. Adaptive control:** Switch between decision strategies based on situation and need. 

**3. Improved fault tolerance:** Redundancy and diversity of models reduce failure risk. 

**4. Custom-built for complexity:** Ideal for domains that demand robustness, such as military AI, autonomous systems, or large-scale automation. 

**==> picture [351 x 199] intentionally omitted <==**

Hybrid AI agents are the Swiss Army knives of AI, versatile, resilient, and tailored to navigate the messiness of real-world decision-making. 

**Autonomous Robot (Hybrid Agent):** • Uses deep RL for motion control. 

• Uses symbolic logic + planning for navigation maps. • Uses unsupervised learning to cluster new environments. 

👉 Here, the agent = hybrid; and its learning process = hybrid learning 

--- end of page.page_number=69 ---

## **NEURAL NETWORKS** 

**Motivation** 

- Despite the outstanding performance of today’s computer there in an ever increasing demand for greater machine intelligence i.e., the machines that can learn, generalize and “think”. 

• 

**Characteristics Of Human Brain** 

-3 pounds in weight & 90 cubic inches volume. 

-Total cell = 100 billion = 10 billion + 90 billion (neurons) (glue/glia cells) -Glia cells are the class of cells intermixed with the neurons in the central nervous systems; providing support function for both metabolic & physical activity; they form matrix in which neurons grow. -Each neuron makes 100 to 1000’s of connections with other neurons. 

- The dream of scientists is to reach for machines that can simulate the stupendous ability of human brain such as vision, language & understanding. 

- Human brain is far more superior to a digital computer at many tasks. 

- For eg. A one year old baby is much better & faster at recognizing objects, faces etc., compared to most advanced AI systems running on a fastest supercomputer. 

**==> picture [312 x 203] intentionally omitted <==**

**What Is Brain?** 

- Brain is a highly complex, nonlinear and parallel information processing system which can organize the its structural constituents called “neurons” so as to perform certain computations many times faster than the fastest digital computer of today. 

- At birth brain has great structures & ability to build up its own rules through the “experience”. 

- “Experience” is build up with time & the most dramatic development of brain is during first two years, but the development continues well beyond that. 

--- end of page.page_number=70 ---

## **Characteristics of Neurons** 

- Mechanically highly sensitive i.e., they respond to pressure. This property forms the basis of sensory receptors, but also causes problems (for eg. Direct mechanical stimulation of a neuron anywhere on its surface activates the cell.) 

- Therefore, mammalian CNS is protected by extraordinary means. 

- Brain is encased in a hard skull. Soft tissues can be easily damaged by being in contact with hard bone, so brain is floated in “cerebrospinal fluid”, which forms hydraulic suspension system. 

- Important Peculiar Property of CNS: 

1. When a neuron dies it is not replaced. 

2. Neurons that do not form correct connections, die. 

3. Coded molecules are transmitted to neurons from their target molecules, to know whether they are correctly “wired up” or “sufficiently activated” by their connections. 

4. There is competition for connections and if appropriate functional contacts are not made the neurons die. 

5. From theoreticians point of view, the inability of neurons to divide provides and imp. ground rule: it is cheating to invent new molecules, the system is to be biologically plausible. 

--- end of page.page_number=71 ---

## **Biological Neuron** 

**==> picture [648 x 410] intentionally omitted <==**

--- end of page.page_number=72 ---

## **Biological Neuron** 

Photo: Osaka University 

--- end of page.page_number=73 ---

• Neurons are cells; have a nucleus and the related cellular metabolic apparatus. 

- Input end has a no. of fine processes called dendrites (due to their resemblance to “tree”. 

- NOTE: “dendro” is a greek word meaning tree.) 

- The variability in shape & size of dendrites reflects analog information processing that 

- neurons perform. 

- Cell body is called Soma. Its size is 10-80μm. 

• A long thin process (few μm), the Axon, leaves the soma & may runs for meters. For eg. single spinal motor neurons in the small of the back can have axons running to toes and can be over a meter long. 

- Axon is the transmission line of neuron. Axon give rise to collateral branches, along with 

- the main branch. 

• When axons reach their final destination, they branch again, called “terminal aborization” 

- (Note: “arbon” is a latin word for “tree”). 

--- end of page.page_number=74 ---

- At the end of axonal branches are complex highly specialized structures called Synapses. Gap across the synaptic junction is 200 nanometers. 

- Nucleus and surrounding machinery have the job of sending nutrients, enzymes & constructional material down the axon to the rest of the cell. 

- Neuron is a very busy place (there are a no. of intracellular mechanisms with different speeds & characteristics). 

- Total length of neuron is 0.01 mm for internal neurons in human brain up to 1m for neurons in limbs. In neurons, inside & outside are quite different in their chemical & electrical properties. 

- Neuron is covered by a thin membrane with remarkable properties. Its function is to separate inside from outside. 

- Membrane is 60 to 70 Armstrong thick & is composed primarily of lipids & proteins. 

- Lipids are arranged in bilayer in which proteins embed themselves, i.e., proteins float in a sort of lipid sea. 

- Proteins can be located inside or outside face of membrane, or pass through the membrane. 

--- end of page.page_number=75 ---

## **Mechanism Of Information Processing** 

## **In Neurons:** 

- Dendrites receive input from other cells. 

- Soma & Dendrites and process 

- integrates the inputs. 

- Information is transmitted along the Axon to the Synapses. 

- Outputs of Synapses provide input to other Neurons/Effectors organ. 

- Synapses allow one cell to influence the activity of other cells. 

- Synapses vary in strengths & these strengths are key to the nature of computations the NNs performs. 

## **Cell Morphology Classification:** 

- Unipolar Cells 

- Have no dendrite emerging from soma 

- A single primary process or branch exists & encompasses both dendrites & axon. 

- These cells are found in invertebrates. 

- Bipolar Cells 

- Have two main processes, one contain dendrites & other consists of axon. 

- Multipolar Cells 

- Have a single axon & one or more dendrites bundles 

## **Why are Neurons slow?** 

- Centre area is a good conductor but not a perfect conductor, therefore in long run losses occur due to resistance of central area. High resistance means hindrance in flow, hence neurons are slow. 

- No insulation is perfect, some current will leak through the membrane in a neuron. So required amount of current will not reach in stipulated time, hence neurons are slow. 

- Large membrane capacity (1microfarads/square cm) & high resistance makes a high time constant, hence neurons are slow. 

--- end of page.page_number=76 ---

## **Artificial Neural Networks** 

• ANN is a massively parallel distributed processor made of simple processing units, which has a natural propensity for storing experimental knowledge and making it available for use. It resembles brain processor in two ways: 

• **Features of Brain Desirable in Artificial Systems:** 

   1. Robust & Fault Tolerant. (Nerve cells in brain die everyday without affecting the performance significantly). 

   2. to a new Flexibility. (Easily adjust environment by “learning”, does not have to be programmed in C or C++. 

- Network the through learning process 

- acquires Knowledge. 

 known as Interconnecting strengths “weights” are used to store knowledge. 

   3. Can deal with information that is fuzzy, probabilistic, noisy or inconsistent. 

   4. Highly parallel. 

- ANN Classification (structure Basis): - 

5. Small, Compact & dissipate very less Power. 6. Adaptability. (Brain stores information in the strengths of interconnections. So a new information is added by adjusting the interconnection strengths, without destroying the old information.) 

- Recurrent (involves feedback). 

- Non-Recurrent (without feedback). 

**==> picture [310 x 192] intentionally omitted <==**

- **ANN Terminology:** 

1. Processing Units (PUs). 2. Interconnections. 

3. Operations. 

4. Update. 

--- end of page.page_number=77 ---

## **Processing Unit/Element (PU/PE)** 

**==> picture [540 x 342] intentionally omitted <==**

--- end of page.page_number=78 ---

## **Interconnections:** 

- Several PU’s are connected according to some topology. 

- Inputs to PU’s come from outputs of another PU’s and /or from external source. 

- Outputs of each unit may be given to several units including itself. 

- Amount of output of each unit received by another unit depends on the strength of connection between units, called weight value. 

## **Update:** Classified in two ways: 

- Synchronous update – Activation values of all units are computed at the same time, assuming a given output state throughout. From these computed activation values, new output state of the network is derived. 

- Asynchronous update – Each unit is updated sequentially, taking current output state of network into account each time. 

- For each unit, output state can be determined from activation value either deterministically or stochastically. 

## **Operations:** 

- Each unit of ANN receives input from other connected units and/or from external source. 

- Weighted sum of inputs is computed at a given instant of time. 

- Activation value determines actual output from output function unit i.e., output state of unit. 

- Output values & other external inputs determine activation & output state of other unit. 

- Synaptic dynamics is followed to adjust weights in order to store given patterns in network 

- Process of adjusting weights is called learning. 

- Once learning process is completed, final set of weight values correspond to LTM (Long Term Memory) function of network. 

- Procedure to incrementally update each of weights is called learning law/algorithm. 

--- end of page.page_number=79 ---

## **Network Topology** 

**==> picture [582 x 316] intentionally omitted <==**

**----- Start of picture text -----**<br>
Feedback<br>Feedforward<br>Inputs<br>Outputs<br>Inputs<br>Outputs<br>**----- End of picture text -----**<br>


--- end of page.page_number=80 ---

## **INSTAR TOPOLOGY** 

**==> picture [648 x 322] intentionally omitted <==**

**----- Start of picture text -----**<br>
F2                                                            …          ….                         …<br>1 2 j N<br>F1                                                          …          …..                          …<br>M<br>2 i<br>1<br>**----- End of picture text -----**<br>


--- end of page.page_number=81 ---

## **OUTSTAR TOPOLOGY** 

**==> picture [660 x 331] intentionally omitted <==**

**----- Start of picture text -----**<br>
F2                                                            …….                         … 1 2 j N<br>M<br>F1                                                          ……..                          … 2 i<br>1<br>**----- End of picture text -----**<br>


--- end of page.page_number=82 ---

## **GROUP OF INSTARS** 

**==> picture [660 x 319] intentionally omitted <==**

**----- Start of picture text -----**<br>
F2                                                            …….                         … 1 2 j N<br>M<br>F1                                                          ……..                          … 2 i<br>1<br>**----- End of picture text -----**<br>


--- end of page.page_number=83 ---

## **GROUP OF OUTSTARS** 

**==> picture [660 x 331] intentionally omitted <==**

**----- Start of picture text -----**<br>
F2                                                            …….                         … 1 2 j N<br>M<br>F1                                                          ……..                          … 2 i<br>1<br>**----- End of picture text -----**<br>


--- end of page.page_number=84 ---

## **BIDIRECTIONAL ASSOCIATIVE MEMORY** 

**==> picture [660 x 295] intentionally omitted <==**

**----- Start of picture text -----**<br>
F2                                                            …….                         … 1 2 j N<br>M<br>F1                                                          ……..                          … 2 i<br>1<br>**----- End of picture text -----**<br>


--- end of page.page_number=85 ---

## **AUTOASSOCIATIVE MEMORY** 

**==> picture [83 x 65] intentionally omitted <==**

…… i M 

1 2 

**==> picture [498 x 175] intentionally omitted <==**

--- end of page.page_number=86 ---

**==> picture [720 x 540] intentionally omitted <==**

**----- Start of picture text -----**<br>
Structure Of ANN<br>**----- End of picture text -----**<br>


--- end of page.page_number=87 ---

## **Problem Solving By ANN** 

**==> picture [455 x 187] intentionally omitted <==**

- The inputs of an ANN are data values grouped together to form a pattern 

- Each data value (component of the pattern vector) is applied to one neuron in the input layer 

- The output value(s) of node(s) in the output layer represent some function of the input pattern 

- In the example above, the ANN maps the input pattern to either one of two classes 

- The ANN produces the output for an accurate prediction, only if the functional relationships between the relevant variables, namely the components of the input pattern, and the corresponding output, have been “learned” by the ANN 

- Any three-layer ANN can (at least in theory) represent the functional relationship between an 

- input pattern and its class 

- It may be difficult in practice for the ANN to learn a given relationship 

--- end of page.page_number=88 ---

**Multilayer Perceptron (MLP)** 

• Nodes are arranged into an input layer, an output layer and one or more hidden layers 

• Also known as the backpropagation network because of the use of error values from the output layer in the layers before it to calculate weight adjustments during training. • Another name for the MLP is the feedforward network. 

**==> picture [431 x 236] intentionally omitted <==**

--- end of page.page_number=89 ---

## **MLP Learning Algorithm** 

- The learning rule for the multilayer perceptron is known as "the generalized delta rule" or the "backpropagation rule“ 

- The generalized delta rule repeatedly calculates an error value for each input, which is a function of the squared difference between the expected correct output and the actual output. 

- The calculated error is backpropagated from one layer to the previous one, and is used to adjust the weights between connecting layers 

- **New weight = Old weight + change calculated from square of error** 

- **Error = difference between desired output and actual output** 

- Training stops when error becomes acceptable, or after a predetermined number of iterations 

- After training, the modified interconnection weights form a sort of internal representation that enables the ANN to generate desired outputs when given the training inputs – or even new inputs that are similar to training inputs 

- This generalization is a very important property 

--- end of page.page_number=90 ---

**Multi-layer Neural Network Employing Backpropagation Algorithm** To illustrate this process let us take an example of three layer neural network with two inputs and one output, which is shown in the picture below: 

**==> picture [457 x 229] intentionally omitted <==**

--- end of page.page_number=91 ---

**==> picture [572 x 309] intentionally omitted <==**

- Each neuron is composed of two units. First unit adds products of weights coefficients and input signals. 

- _e_ 

- The second unit realize nonlinear function, called neuron activation function. Signal is adder output signal, and _y = f(e)_ is output signal of nonlinear element. 

- • Signal _y_ is also output signal of neuron. 

--- end of page.page_number=92 ---

- To teach the neural network we need training data set. The training data set consists of _x x z_ . 

- input signals( _1_ and _2_ ) assigned with corresponding target (desired output) 

- _w_ 

- Pictures below illustrate how signal is propagating through the network, Symbols _(xm)n x n_ 

- represent weights of connections between network input _m_ and neuron in input layer. _n_ . 

- Symbols _yn_ represents output signal of neuron 

**==> picture [415 x 211] intentionally omitted <==**

--- end of page.page_number=93 ---

**==> picture [444 x 200] intentionally omitted <==**

**==> picture [444 x 205] intentionally omitted <==**

--- end of page.page_number=94 ---

# • _w_ Propagation of signals through the hidden layer. Symbols _mn_ represent weights of _m n_ connections between output of neuron and input of neuron in the next layer. 

**==> picture [406 x 180] intentionally omitted <==**

**==> picture [406 x 180] intentionally omitted <==**

--- end of page.page_number=95 ---

• Propagation of signals through the output layer. 

**==> picture [410 x 176] intentionally omitted <==**

• In the next algorithm step the output signal of the network _y_ is compared with the desired output value (the target), which is found in training data set. The difference is called error signal _d_ of output layer neuron. 

**==> picture [416 x 193] intentionally omitted <==**

--- end of page.page_number=96 ---

• It is impossible to compute error signal for internal neurons directly, because output values of these neurons are unknown. The idea is to propagate error signal _d_ (computed in single teaching step) back to all neurons, which output signals were input for discussed neuron. 

**==> picture [371 x 206] intentionally omitted <==**

**==> picture [366 x 200] intentionally omitted <==**

--- end of page.page_number=97 ---

# • _w_ The weights' coefficients _mn_ used to propagate errors back are equal to this used during computing output value. Only the direction of data flow is changed. 

**==> picture [385 x 204] intentionally omitted <==**

**==> picture [354 x 210] intentionally omitted <==**

**==> picture [348 x 212] intentionally omitted <==**

--- end of page.page_number=98 ---

• When the error signal for each neuron is computed, the weights coefficients of each neuron input node may be modified. In formulas below _df(e)/de_ represents derivative of neuron activation function (which weights are modified). 

**==> picture [416 x 254] intentionally omitted <==**

--- end of page.page_number=99 ---

**==> picture [416 x 245] intentionally omitted <==**

**==> picture [416 x 249] intentionally omitted <==**

--- end of page.page_number=100 ---

**==> picture [414 x 242] intentionally omitted <==**

**==> picture [414 x 250] intentionally omitted <==**

--- end of page.page_number=101 ---

**==> picture [422 x 231] intentionally omitted <==**

- Coefficient _η_ affects network teaching speed. There are a few techniques to select this 

- parameter: 

1. The first method is to start teaching process with large value of the parameter. While weights coefficients are being established the parameter is being decreased gradually. 

2. The second, more complicated, method starts teaching with small parameter value. During the teaching process the parameter is being increased when the teaching is advanced and then decreased again in the final stage. Starting teaching process with low parameter value enables to determine weights coefficients signs. 

--- end of page.page_number=102 ---

## **BACK-PROPAGATION TRAINING ALGORITHM** 

- Back Propagation is also known as "Backward Propagation of Errors" is a method used to train neural network . Its goal is to reduce the difference between the model’s predicted output and the actual output by adjusting the weights and biases in the network. 

- It works iteratively to adjust weights and bias to minimize the error between the actual output of a multilayer feed-forward perceptron and the desired output. In each epoch the model adapts these parameters by reducing loss by following the error gradient. 

- It often uses optimization algorithms like gradient descent or stochastic gradient descent. The algorithm computes the gradient using the chain rule from calculus allowing it to effectively navigate complex layers in the neural network to minimize the cost function. 

- It requires continuous differentiable non-linearities. 

- Assume a sigmoid logistic non-linearity is used where the function f(α) is 

= 1 . f(α) 1+ e[-(α-θ)] 

--- end of page.page_number=103 ---

# **ANN Architecture Used for the Derivation of Error Expression for the Back-propagation Algorithm** 

X1 x **h** 1 **1** yyy11 x x **h** 2 **2** X2 yy22 2 . 

yyy11 

. . x h x h Xp 3 3 yy3n m p 

--- end of page.page_number=104 ---

## **Back Propagation Algorithm** 

• **Start** 

• **Initialize weights and biases randomly** 

• **Forward pass** (input → hidden → output) 

• **Compute error** (difference between desired output and actual output) 

• **Backward pass** (calculate gradients using δ terms) 

• **Update weights & biases** (gradient descent update rule) 

• **Check stopping criterion** (error tolerance or max epochs) 

•If **No** , loop back to forward pass 

•If **Yes** , stop 

• **End** 

**Step 1: Initialize weights and offsets:** Set all weights and node offsets to small random values **Step 2: Present Input and Desired Outputs:** Present a continuous valued input vector 

x0,x1…xP-1 and specify the desired output d0,d1…dN-1. 

. **Step 3: Calculate Actual Outputs:** Use the nonlinearity and calculate outputs y0,y1…yN-1 

**Step 4: Adapt Weights** 

Adjust weights by: 

w ij(t+1) = wij(t) + η δj xi 

Where η is a learning parameter, and δj is an error term for node j. if node j is an output node. Convergence is sometimes faster if a momentum term m is added and weight changes are smoothed by: wij(t+1) = wij(t) + η δj xi + m (wij(t) - wij(t-1)), where 0 < m < 1 **Step 5: Repeat steps 2 to 4.** 

--- end of page.page_number=105 ---

## **Derivation for Error in Back-Propagation Algorithm** 

Initialization: 

x= input vector of input layer for unit k. 

h=weight vector of input layer for unit k. 

v=input vector of hidden layer for unit j. 

g= weight vector of hidden layer for unit j. 

y=output vector of output layer. w = weight for i[th] neuron of output layer  to j[th] neuron of hidden layer. ij w = weight for j[th] neuron of hidden layer  to k[th] neuron of input layer. jk 

--- end of page.page_number=106 ---

## Input of hidden layer: 

p 

hj = ∑wjk * xk ………………………..(1) k=1 

Output of hidden layer: 

v j =   f(hj) 

v j =  1/(1+ e[-hj] )  ………..………….(2) 

Input of output layer: 

m 

gi= ∑wij * vj ……………………………..(3) j=1 

--- end of page.page_number=107 ---

## Output of output layer: 

yi = f(gi) 

yi = 1/(1+e[-gi] )  ………………….…………..(4) 

Error function: 

n E(t)= 1/2 ∑(yid - yi )[2] ………………………..(5) i=1 

Weight function: 

w (t+1)= w (t) + ∆w (t)…………….……….(6) ij ij ij 

∆w (t) = - η ∂E(t) ij 

∂w (t) ij 

………….………………(7) 

--- end of page.page_number=108 ---

Updating weights between output layer and hidden layer: 

n 

* ∂E(t) = ∑  ∂E(t) ∂yi ……………(8) ∂wij(t)     i=1  ∂yi ∂wij(t) 

From equation (4) and (5) we get equation (9) as below: 

yi = 1/(1+e[-gi] ) ………………….…………..(4) 

E(t)= 1/2 ∑(yid - yi )[2 ] ………………………..(5) 

∂E(t) = - (yid - yi ) ………… ……………(9) 

∂yi 

--- end of page.page_number=109 ---

From Eqn (4), the derivative of the output activation yi with respect to weight w ij 

= ∂yi ∂   (1+e[-gi] )[-1] ∂w (t)      ∂w ij ij 

Expressing Eqn (4) in terms of the partial derivative (output yi w.r.t. weight as product of two partial derivatives) 

= ∂yi ∂yii ∂wij(t)     ∂gi 

= ∂yii * ∂gi 

∂w ij 

From the above two expressions and Eqn no. (3) 

m 

-gi -1 = ∂yi ∂ (1+e ) ∂wij(t)             ∂gi 

* ∂ v (∑ w ) ij j j=1 

∂w ij 

--- end of page.page_number=110 ---

## Expanding the expression of the previous slide 

∂yi = -1(-e[-gi] ) ∂w (t)       (1+e[-gi] )[2] ij 

*[v] j[……………(10)] 

We know from Eqn. (4) yi = 1/(1+e[-gi] ) 

Subtracting this above sigmoid output from 1 (LHS and RHS) 

- (1-yi)     =   1- 1/(1+e[-gi] ) 

Solving further 

(1-yi)   =  e[-gi] /(1+e[-gi] ) 

--- end of page.page_number=111 ---

Multiplying yi and (1-yi) from previous slide to get yi(1-yi)   = e[-gi] /(1+e[-gi] )[2] 

Substituting this (above) value in Eqn (10) to get 

∂yi = (1-yi) yi * vj…………………………(11) ∂w (t) ij 

Substituting the value of Eqn (9) and Eqn(11) in Eqn (8) to get 

∂ * E(t) = -(yid - yi ) (1-yi) yi * vj …………(12) ∂w (t) ij 

Say Error term is δi (the sigmoid derivative and the difference between desired and actual output) is 

δi = -yi(1-yi)(yid – yi)-----------------------------(13) 

--- end of page.page_number=112 ---

## From Eqn. (12) and (13) 

= -[n] Σ v ∂E(t) i=1 δi j-------------------------------(14) ∂w (t) ij 

We know Eqn. (7) is          ∆w (t) = - η ∂E(t) ij ∂w (t) ij 

Therefore from Eqn. (7) and (14) 

∆wij(t) = η δi vj-----------------------------------(15) 

Hence updated weight (From Eqn (6) and (15)) will be **w v ij(t+1) = wij (t) + η δi j-----------------------(16)** 

Convergence is sometimes faster if a momentum term m is added and weight changes are smoothed by: **w ij(t+1) = wij(t) + η δj xi + m (wij(t) - wij(t-1)) ----------------(17)** 

where 0 < m < 1 

--- end of page.page_number=113 ---

## **Flow of Back Propagation Algorithm** 

**==> picture [444 x 327] intentionally omitted <==**

• **Back Propagation** improve neural networks over time. 

**1.Efficient Weight Update** : It computes the gradient of the loss function making it possible to update weights efficiently. 

**2.Scalability** : The algorithm scales well to networks with multiple layers and complex architectures making deep learning feasible. **3.Automated Learning** : The becomes learning process automated and the model can adjust itself to optimize its performance. 

--- end of page.page_number=114 ---

**Flow Diagram Of Back-Propagation Algorithm.** 

**==> picture [390 x 460] intentionally omitted <==**

--- end of page.page_number=115 ---

## • **Advantages Of Back Propagation For Neural Network Training** 

**1.Ease of Implementation:** Back Propagation is beginner-friendly requiring no prior neural network knowledge and simplifies programming by adjusting weights with error derivatives. 

**2.Simplicity and Flexibility:** Its straightforward design suits a range of tasks from basic feedforward to complex convolutional or recurrent networks. 

**3.Efficiency** : Back Propagation accelerates learning by directly updating weights based on error especially in deep networks. 

**4.Generalization:** It helps models generalize well to new data improving prediction accuracy on unseen examples. 

- **5.Scalability:** The algorithm scales efficiently with larger datasets and more complex networks making it ideal for large-scale tasks. 

• **Challenges With Back Propagation** 

**1.Vanishing Gradient Problem** : In deep networks the gradients can become very small during Back Propagation making it difficult for the network to learn. This is common when using activation functions like sigmoid or tanh. 

**2.Exploding Gradients** : The gradients can also become excessively large causing the network to diverge during training. 

**3.Overfitting:** If the network is too complex it might memorize the training data instead of learning general patterns. 

--- end of page.page_number=116 ---

## **Weight Verses Sum Of Square Error** 

Local minima in MLPs are small valleys in the error surface that can trap gradient descent, preventing the network from reaching the best solution — but techniques like good initialization, momentum, and advanced optimizers help overcome this. 

**==> picture [631 x 388] intentionally omitted <==**

--- end of page.page_number=117 ---

## **Learning Difficulties In Multilayer Perceptron (Local Minima)** 

• **What is Local Minima?** 

In training an MLP, we minimize an error function (like Mean Squared Error or Cross-Entropy). The error surface is non-convex with many valleys and hills. A local minimum is a point where the error is lower than nearby points but not the lowest possible (global minimum). 

## • **Why It Happens in MLP** 

MLPs have nonlinear activation functions and multiple layers of weights, leading to a complex error surface with many local minima and saddle points. Gradient Descent (backpropagation) updates weights in the direction of steepest descent, but if it reaches a local minimum, it may get stuck. 

- **Effects of Local Minima** 

- Training may stop prematurely without achieving the best accuracy. 

- The model may perform sub-optimally on test data. 

- Leads to slow convergence or poor generalization. 

• **Visual Intuition** 

- The error surface is like a mountain valley landscape: 

- Global Minimum = the deepest valley (best solution). 

- Local Minima = small dips where the algorithm might get trapped. 

- Gradient Descent is like a ball rolling downhill that may stop in a small dip instead of reaching the deepest valley. 

--- end of page.page_number=118 ---

## **Solutions / Remedies to Overcome Local Minima in MLPs** 

• **Lowering the Gain Term (Learning Rate) Progressively** The learning rate controls how fast weights are updated. A high rate may cause oscillations, while too low may slow convergence. By gradually reducing the learning rate as training progresses, the updates become finer and the network avoids overshooting the global minimum. 

- **Addition of More Nodes (Network Capacity)** 

Too few hidden nodes may lead to underfitting where the ANN cannot represent the pattern adequately. Adding more nodes (or layers) increases the representation power, allowing the model to better capture complex patterns and reducing the likelihood of poor local minima. 

- **Introduction of a Momentum Term** 

Momentum introduces a fraction of the previous weight update into the current update. It smooths oscillations and helps the gradient descent roll over shallow local minima instead of getting stuck. The momentum term is usually a small value in the range 0–1. 

## • **Addition of Random Noise** 

Injecting small random noise into weights during training perturbs the network. This can 'kick' the ANN out of a local minimum and move it to a different region of the error surface. Often combined with stochastic training methods for more robustness. 

• **Better Weight Initialization** 

Poor initialization can trap the model in bad local minima. Methods like Xavier Initialization (for sigmoid/tanh) and He Initialization (for ReLU) ensure weights start in a balanced range, improving convergence. 

--- end of page.page_number=119 ---

• **Stochastic Gradient Descent (SGD)** Instead of computing the gradient on the entire dataset, SGD uses random mini-batches. This randomness injects noise into the updates, helping the optimizer escape local minima and saddle points. 

• **Adaptive Optimizers** Optimizers like Adam, RMSProp, Adagrad adjust the learning rate for each parameter dynamically. They are better at navigating complex, non-convex error surfaces, reducing the chance of getting stuck. 

• **Regularization Techniques** Methods like Dropout and Weight Decay (L2 penalty) simplify the error surface. They prevent overfitting and smooth out sharp minima, encouraging the optimizer to find flatter and better generalizing minima. 

• **Large and Diverse Training Data** More diverse data helps in shaping a smoother error landscape. Reduces irregularities and allows the optimizer to move more reliably towards the global minimum. 

**Summary:** Combining strategies like progressive learning rate decay, momentum, noise injection, adaptive optimizers, and good initialization makes MLP training more robust and significantly reduces the risk of being trapped in local minima. 

--- end of page.page_number=120 ---

## **Cascade Back-Propagation (CBP)** 

- Cascade backpropagation is an incremental neural network training approach where new 

- hidden neurons are added one by one during learning, rather than fixing the architecture in advance. Each new neuron is trained to minimize the residual error of the network. 

**1. Start & Initial Weight Calculation:** The process begins with an initial set of weights, often calculated using the pseudo-inverse technique to approximate an initial mapping. These weights are then downloaded (assigned) into the network. 

**2. Training Data Phase:** The training dataset is fed to the network. Errors are computed between predicted and actual outputs. Standard backpropagation is applied to adjust weights. 

**3. Error Monitoring with Cross-Validation:** The cross-validation data checks whether the network’s error falls below a threshold: If Yes →Stop training and move to performance testing; If No →Training continues with adjustments. 

**4. Adaptive Learning Rate Adjustment:** During training, if the error reduction slows or oscillates, the system tries to adapt the learning rate: Reduce Learning Rate: When error reduction is unstable; Freeze Learning Rate: If the learning stabilizes for current weights. 

--- end of page.page_number=121 ---

**5. Adding New Hidden Neurons (Cascade Growth):** If performance is still not adequate, the algorithm checks whether the learning rate is below a threshold level. If Yes, a new hidden neuron is added to the network. This neuron connects to all inputs and previous hidden neurons (cascade connectivity). Each added neuron improves the representational power of the network. 

**6. Weight Update Process:** Once a neuron is added, weight changes are computed again. Training resumes with the updated architecture (original network + new neuron). This process is iterative: new neurons are added only when needed. 

**7. Validation and Stopping:** The validating network checks performance using unseen data (cross-validation/test sets). If errors are below the threshold level, training stops, and the network is considered successfully trained. 

- **Key Features of Cascade Backpropagation** 

- Dynamic Growth: The network grows incrementally by adding hidden neurons. 

- Efficient Representation: Each new neuron focuses on reducing residual error. 

- Avoids Overfitting: Training stops when error threshold is reached. 

- Flexible Learning Rate: Adjusted dynamically (reduce/freeze). 

- Validation-Based Control: Cross-validation ensures generalization. 

--- end of page.page_number=122 ---

**Cascade Back-Propagation (CBP)** as shown in the diagram, starts with initial weights, trains the network, adaptively adjusts learning rate, and if needed, adds new hidden neurons until the performance meets a desired error threshold, ensuring both adaptability and efficiency. 

**==> picture [599 x 410] intentionally omitted <==**

--- end of page.page_number=123 ---

## **Recent Papers Using Back-propagation (BP)** 

**1. A. Renner, F. Sheldon, A. Zlotnik, L. Tao, and A. Sornborger** , “The backpropagation algorithm implemented on spiking neuromorphic hardware,” _Nature Communications_ , vol. 15, Art. 9691, 2024, doi: **10.1038/s41467-024-53827-9** . _Takeaway:_ First full **on-chip spiking backprop** on Intel Loihi—exact BP with synfire-gated control, competitive accuracy and strong energy-latency profile. NatureIDEAS/RePEc 

**2. G. Nápoles, A. Jastrzebska, I. Grau, and Y. Salgueiro** , “Backpropagation through time learning for recurrence-aware longterm cognitive networks,” _Knowledge-Based Systems_ , vol. 295, Art. 111825, 2024, doi: **10.1016/j.knosys.2024.111825** . _Takeaway:_ Proposes a **modified BPTT** for r-LTCN models, mitigating vanishing gradients and improving multi-output regression accuracy on 20 datasets. Eindhoven Tech Research Portal 

**3. R. Boone and P. Li** , “Backpropagation-based learning with local derivative approximation and memory replay in biologically plausible neural systems,” _Neurocomputing_ , vol. 634, Art. 129804, 2025, doi: **10.1016/j.neucom.2025.129804** . _Takeaway:_ Introduces a **biologically plausible BP approximation** (local-derivative + replay) for spiking systems while retaining BP-level performance. ResearchGateOSTI 

**4. X. Niu, N. Wei, and Y. Zhou** , “Improved polar motion prediction using a genetic algorithm optimized backpropagation neural network and effective angular momentum functions,” _Advances in Space Research_ , 2025, doi: **10.1016/j.asr.2025.04.065** . _Takeaway:_ Uses **GA-optimized BPNN** with geophysical features to achieve state-of-the-art polar-motion forecasting. ScienceDirectOUCI 

**5. A. A. Al-Dulaimi** _**et al**_ **.** , “AE-BPNN: autoencoder and backpropagation neural network-based model for lithium-ion battery state of health estimation,” _Scientific Reports_ , vol. 15, Art. 29193, 2025, doi: **10.1038/s41598-025-12771-4** . _Takeaway:_ **Autoencoder + BP** pipeline on EIS data for accurate Li-ion **SOH estimation** ; compares SCG vs. Resilient BP optimizers. Nature 

**6. L. Zhou** _**et al**_ **.** , “Optimization of the heat recovery performance of enhanced geothermal system based on PSO-GA-BP neural networks and analytic hierarchy process,” _Scientific Reports_ , vol. 15, Art. 21472, 2025, doi: **10.1038/s41598-025-07509-1** . _Takeaway:_ **PSO-GA-BP** hybrid optimizes geothermal EGS parameters, showcasing BP within a high-impact energyengineering workflow. Nature 

--- end of page.page_number=124 ---

**SENSING:** Collecting raw sensory information from the environment. _AI Example:_ A self-driving car uses cameras, LIDAR, and radar to sense lane markings, traffic signals, and nearby vehicles. _Human Parallel:_ Eyes and ears gather light and sound. **ACQUISITION** : Converting raw sensory data into a usable format and storing it. _AI Example:_ The car’s camera images are digitized and stored as pixel arrays; radar signals are transformed into distance measurements. _Human Parallel:_ Visual impressions are stored briefly in short-term memory. 

**PERCEPTION:** Interpreting acquired data to give it meaning and context. _AI Example:_ The car’s vision system identifies objects — e.g., a red traffic light, pedestrian crossing, or another vehicle. _Human Parallel:_ Recognizing a red circle as a “stop light.” 

_**(Cognitive Triangle is a tool that highlights the relationship between how we feel, think, and behave.)**_ 

## **COGNITION CYCLE** 

**==> picture [433 x 244] intentionally omitted <==**

## **PLANNING:** Deciding the next action based on goals, rules, and 

perceived environment. 

_AI Example:_ The self-driving car decides to slow down or stop at the red light, or calculate a new route if there’s a roadblock. _Human Parallel:_ Deciding to press the brake pedal or take an alternate street. 

**ACTION:** Executing the chosen plan in the environment. _AI Example:_ The car’s control system applies brakes, steers, or accelerates as per the plan. _Human Parallel:_ Actually pressing the brake pedal or turning the wheel. 

**CYCLE CONTINUATION:** After ACTION, the system SENSES the updated environment again (e.g., light turns green →cycle restarts). 

--- end of page.page_number=125 ---

## **Table for Decision Trees Question solved in the class** 

**==> picture [710 x 341] intentionally omitted <==**

--- end of page.page_number=126 ---

## **Clustering** 

--- end of page.page_number=127 ---

## • **What is similarity?** 

## The quality of state of being similar, likeness, resemblance, etc as similarity features. • **Similarity is very hard to define.** 

**==> picture [638 x 403] intentionally omitted <==**

--- end of page.page_number=128 ---

## **Topics of clustering covered in class should also be studied for End sem** 

--- end of page.page_number=129 ---

## **Density-Based Clustering** 

- Traditional clustering methods such as k-means assume that clusters are 

- _spherical_ and require a pre-specified number of clusters (k). 

- However, real-world data often contain arbitrarily shaped clusters, noise, and 

- non-uniform densities. 

• To overcome these limitations, density-based clustering defines clusters as regions in the data space with higher density of points separated by regions of lower density. 

- Imagine data points plotted in 2D space. Dense regions correspond to clusters, 

- while sparse regions correspond to noise or boundaries. 

• **A cluster is a connected dense region of points.** 

- If each data point is a star in the night sky, dense constellations of stars form 

- clusters, and isolated stars represent noise. 

--- end of page.page_number=130 ---

## **Concepts** 

## **Term** 

## **Density** 

**Neighborhood (ε-neighborhood) Core Point** 

**Border Point Noise (Outlier)** 

**Density Reachability** 

**Density Connectivity** 

**Meaning** 

Number of points within a given neighborhood radius (ε) 

The region within distance ε of a point A point with ≥ _MinPts_ neighbors within ε 

Lies within ε of a core point but has < _MinPts_ neighbors 

Neither core nor border point 

One point is reachable from another if it lies within its ε neighborhood chain of core points 

Two points belong to the same cluster if both are density-reachable from some common core point 

--- end of page.page_number=131 ---

## **General Working of Density-Based Algorithms** 

1.Choose parameters **ε** and **MinPts** . 

- 2.For each unvisited point: 

   1. Compute its ε-neighborhood. 

   2. If it contains ≥ MinPts, start a new cluster and expand by adding all density-reachable points. 

   3. If not, mark it as noise. 

3.Continue until all points are processed. 

- Outcome → **Clusters of arbitrary shapes** + **Noise** . 

- **points** 

--- end of page.page_number=132 ---

## **Algorithm** 

**DBSCAN** 

**OPTICS** 

**HDBSCAN** 

**DENCLUE** 

## **Density-Based Algorithms** 

**Handles Varying Density?** 

**Full Form Key Feature** Density-Based Spatial Clustering Core–border–noise of Applications model with Noise Ordering Points To Extracts ordering Identify Clustering representing Structure density 

❌ Difficult 

representing ✅ Yes density Builds hierarchical ✅ Excellent tree of clusters Uses mathematical density functions ✅ Yes, parametric (Gaussian kernels) 

Hierarchical Density-Based Spatial Clustering 

DENsity-based CLUstEring 

--- end of page.page_number=133 ---

## **DBSCAN** 

**Density-Based Spatial Clustering of Applications with Noise** 

- DBSCAN is one of the most powerful unsupervised clustering algorithms used to discover clusters of arbitrary shape and to identify outliers (noise points) in spatial or high-dimensional data. 

- Unlike _k-means_ or _hierarchical clustering_ , DBSCAN does not require 

- specifying the number of clusters in advance. 

- It groups together data points that are closely packed (points with many nearby neighbors) and marks as outliers points that lie alone in low-density regions. 

- DBSCAN defines clusters as dense regions of data points separated by regions of lower density. 

- The idea is that a cluster is a continuous region of high point density. 

--- end of page.page_number=134 ---

## • **Working of DBSCAN** 

1.Select a point (P) not yet visited. 

2.Find all points within ε (the neighborhood of P). 

3.If the number of neighbors ≥ MinPts, mark P as a core point and form a cluster. 

4.Expand the cluster by recursively including all density-reachable points: 

If a neighbor is also a core point, include its neighbors too. 

5.If the point has fewer than MinPts neighbors, mark it as noise (temporary). 

6.Continue until all points are visited. 

--- end of page.page_number=135 ---

## **DBSCAN Advantages and Limitations** 

**Aspect No need for K Arbitrary shapes Noise detection Scalability** 

**DBSCAN Advantage** 

Automatically finds number of clusters Handles circular, spiral, irregular clusters Identifies and excludes outliers Works efficiently on large spatial databases 

**Aspect Parameter sensitivity** 

**Varying density** 

**High dimensions** 

**Limitation** Choice of ε and MinPts crucial 

Struggles with datasets having clusters of different densities Distance metrics lose meaning (curse of dimensionality) 

--- end of page.page_number=136 ---

## **DBSCAN vs K-Means** 

**Feature** 

**DBSCAN** 

## **Input** 

ε, MinPts 

Arbitrary (nonspherical) 

**Cluster shape** 

Handled as noise 

**Outliers** 

Moderate to high Densitybased 

**Scalability Interpreta bility** 

**K-Means** 

K (number of clusters) 

Spherical 

Forced into clusters 

High 

Centroidbased 

## **Practical Applications of DBSCAN** 

**Domain** 

**Use Case** 

Detect dense populated areas, hotspots Earthquake epicenter detection Segmentation of color/intensity clusters[[Fraud or intrusion ]] detection Path clustering, swarm grouping Star/galaxy distribution clustering 

**Spatial Analysis** 

**Geoscience** 

**Image Processing** 

> [[Fraud or intrusion ]] **Anomaly Detection** 

**Robotics & UAVs Astronomy** 

--- end of page.page_number=137 ---

**Variant** 

**OPTICS** (Ordering Points To Identify Clustering Structure) **HDBSCAN DBSCAN++ GDBSCAN** 

## **Variants of DBSCAN** 

**Feature** Handles varying density clusters 

**Use** Hierarchical density clustering 

Hierarchical + probabilistic Uses k-means++ seeding for improved efficiency Generalized version for non-Euclidean distances 

High-dimensional, adaptive Large-scale data Graph and categorical data 

--- end of page.page_number=138 ---

**==> picture [676 x 412] intentionally omitted <==**

--- end of page.page_number=139 ---

**==> picture [647 x 394] intentionally omitted <==**

--- end of page.page_number=140 ---

**==> picture [672 x 412] intentionally omitted <==**

--- end of page.page_number=141 ---

## • **Steps in the DBSCAN Algorithm** 

**1.Identify Core Points** : For each point in the dataset count the number of points within its eps neighborhood. If the count meets or exceeds MinPts mark the point as a core point. 

**2.Form Clusters** : For each core point that is not already assigned to a cluster create a new cluster. Recursively find all density-connected points i.e points within the eps radius of the core point and add them to the cluster. 

**3.Density Connectivity** : Two points a and b are density-connected if there exists a chain of points where each point is within the eps radius of the next and at least one point in the chain is a core point. This chaining process ensures that all points in a cluster are connected through a series of dense regions. 

**4.Label Noise Points** : After processing all points any point that does not belong to a cluster is labeled as noise. 

--- end of page.page_number=142 ---

## **DBSCAN** 

In DBSCAN we need not specify the number of clusters. 

Clusters formed in DBSCAN can be of any arbitrary shape. 

It can work well with datasets having noise and outliers 

In DBSCAN two parameters are 

required for training the Model 

**K-Means** 

It is very sensitive to the number of clusters (k), which must be specified in advance. 

Clusters formed are spherical or convex in shape 

It does not work well with outliers data. Outliers can skew the clusters in K-Means to a very large extent. 

In K-Means only one parameter is required is for training the model 

--- end of page.page_number=143 ---

**OPTICS (Ordering Points To Identify the Clustering Structure)** 

• **Goal:** Overcome DBSCAN’s limitation of fixed ε by analyzing density variations. 

• **Working:** 

1. Orders points based on **reachability distance** (minimum distance at which each point becomes reachable from another). 2. Produces a **reachability plot** — valleys in this plot correspond to clusters of different densities. 

• **Advantages:** 

1. No need for a global ε. 2. Reveals hierarchical relationships among clusters. 

--- end of page.page_number=144 ---

## **HDBSCAN (Hierarchical DBSCAN)** 

- Extends DBSCAN by building a hierarchy of clusters based on variable density 

- thresholds. 

• **Steps:** 

1.Compute mutual reachability distance (a smoothed density measure). 2.Construct a Minimum Spanning Tree (MST) of points based on these distances. 

- 3.Condense the hierarchy and extract stable clusters using persistence criteria. 

- **Advantages:** 

1. Automatically selects optimal clusters. 2. Handles varying densities well. 

3. Produces probabilistic cluster memberships. 

--- end of page.page_number=145 ---

## **DENCLUE** 

**(Density-based Clustering Using Gaussian Density Functions)** 

- **Principle:** 

• Models data density as a sum of **influence functions** (often Gaussian kernels). 

• Finds **density attractors** — local maxima of density function → cluster centers. 

• f(x)=∑i=1ne−∣∣x−xi∣∣22σ2f(x) = \sum_{i=1}^{n} e^{-\frac{||xx_i||^2}{2\sigma^2}}f(x)=i=1∑n​e−2σ2∣∣x−xi​∣∣2​ **Advantages:** • Mathematical and continuous definition of density. • Can merge small dense subclusters effectively. 

--- end of page.page_number=146 ---

## **Comparison Summary** 

**Aspect K-Means DBSCAN OPTICS HDBSCAN** Requires _k_ ? ✅ Yes ❌ No ❌ No ❌ No Shape of Spherical Arbitrary Arbitrary Arbitrary Clusters Handles Noise ❌ No ✅ Yes ✅ Yes ✅ Yes Handles Varying ❌ Poor ❌ No ✅ Moderate ✅ Excellent Densities Ordered Hierarchical Output Flat Clusters Flat + Noise Structure Clusters 

--- end of page.page_number=147 ---

## **Strengths of Density-Based Clustering** 

**Advantage No need to specify k Arbitrary shape detection Noise identification Robustness** 

**Applicable domains** 

**Description** 

Automatically determines cluster count Works for non-spherical clusters Separates outliers naturally 

Resistant to data order and initialization Spatial, image, sensor, and anomaly data 

## **Limitations** 

**Limitation** 

Sensitive to ε and MinPts 

Varying densities 

High-dimensional data 

Computational cost 

**Reason** 

Wrong parameter choice → wrong clusters Difficult for DBSCAN (handled by OPTICS/HDBSCAN) Distance metrics lose meaning (curse of dimensionality) 

For very large datasets unless optimized (e.g., with KD-tree/R-tree index) 

--- end of page.page_number=148 ---

## **Real-World Example** 

• **Dataset:** Earthquake epicenters (latitude, longitude) **Goal:** Identify seismically active zones. • DBSCAN groups nearby quakes (core + border points). • Sparse isolated quakes marked as noise. • OPTICS can reveal clusters of both mild and severe intensity. • **Result:** Natural grouping of earthquake belts along tectonic boundaries. 

**Domain Geographical Information Systems (GIS)** 

**Image Analysis Astronomy Biology** 

**Robotics / UAVs Cybersecurity** 

**Use Case** 

Identifying densely populated or highrisk zones 

Object segmentation using pixel density 

Grouping galaxies or star clusters Clustering gene expression data Mapping exploration regions based on density Anomaly or intrusion detection (outlier clusters) 

--- end of page.page_number=149 ---

## **Cluster Validity Analysis** 

## **Cluster evaluation** (also called _cluster validity analysis_ ) helps determine: 

- How well the data has been grouped 

- How cohesive and distinct the clusters are 

- The optimal number of clusters 

**Objective** 

**Cohesion** 

**Separation** 

**Stability** 

**Interpretability** 

**Description** 

Points in the same cluster should be close together (intra-cluster similarity). 

Points in different clusters should be far apart (inter-cluster dissimilarity). 

Clusters should remain consistent under small data perturbations. Results should make intuitive and domain sense. 

--- end of page.page_number=150 ---

## **Types of Cluster Evaluation Measures** 

## • : Clustering quality measures are classified into **three major types** 

**Type Basis Examples** Evaluate the clustering SSE, Silhouette Coefficient, **Internal Measures** structure using intrinsic Dunn Index, Davies– data features only Bouldin Index Compare clustering results Rand Index, Purity, F- **External Measures** to external “ground truth” measure, NMI labels Compare multiple **Relative Measures** clusterings or parameter Elbow Method, Gap Statistic settings 

--- end of page.page_number=151 ---

# • **Internal Measures:** Internal indices evaluate how compact and wellseparated the clusters are. 

• **Cohesion and Separation** 

**==> picture [639 x 310] intentionally omitted <==**

--- end of page.page_number=152 ---

## **SSE (Sum of Squared Errors)** 

**==> picture [449 x 148] intentionally omitted <==**

## **Silhouette Coefficient** 

**==> picture [491 x 298] intentionally omitted <==**

--- end of page.page_number=153 ---

## **Dunn Index** 

**==> picture [555 x 158] intentionally omitted <==**

## **Davies–Bouldin (DB) Index** 

**==> picture [539 x 220] intentionally omitted <==**

--- end of page.page_number=154 ---

## **Calinski–Harabasz Index (Variance Ratio)** 

**==> picture [494 x 120] intentionally omitted <==**

## **Ideal Cluster Characteristics** 

**Property Cohesion Separation Stability Simplicity Interpretability** 

**Desired Behavior** High (points tightly packed) High (clusters well apart) High (robust to data changes) Moderate number of clusters Semantically meaningful results 

--- end of page.page_number=155 ---

**Agent-Based Data Mining (ABM)** 

--- end of page.page_number=156 ---

## **Agent-Based Data Mining (ABM)** 

• ABM is an advanced paradigm that combines data mining techniques with multi-agent systems (MAS) to analyze large, distributed, and dynamic datasets intelligently and autonomously. 

• Definition: Agent-based data mining involves the use of autonomous, intelligent software agents that can cooperate, communicate, and learn to perform data tasks—such as mining classification, clustering, prediction, or pattern discovery—across distributed environments. • It’s “data mining performed by intelligent agents working together in a distributed system.” 

--- end of page.page_number=157 ---

- **Why Agent-Based Mining?** 

- Traditional data mining assumes centralized data and 

- control. Modern environments (IoT, web, cloud systems) are distributed, heterogeneous, and dynamic — making agentbased mining ideal. 

- Advantages: 

- Handles distributed or decentralized data sources 

- Reduces communication overhead 

- Provides scalability and flexibility 

- Enables adaptive and real-time learning 

- Improves fault tolerance and autonomy 

--- end of page.page_number=158 ---

**Architecture of Agent-Based Mining System** 

- **1.User Interface Agent:** Interacts with the user, interprets goals. 

- **2.Data/Knowledge Agent:** Manages local databases or data streams. 

- **3.Mining Agent:** Executes mining algorithms (e.g., clustering, association). 

- **4.Coordinator/Broker Agent:** Allocates tasks among agents and aggregates results. 

- **5.Communication Agent:** Enables inter-agent communication and result sharing. 

- **6.Learning Agent:** Improves mining strategies using past performance (reinforcement learning, etc.). 

--- end of page.page_number=159 ---

• **Working Process** 

**1.Problem Decomposition:** The main mining task is divided among multiple agents. **2.Local Mining:** Each agent performs mining on its data subset (e.g., local clustering). 

**3.Knowledge Exchange:** Agents share intermediate results. **4.Result Integration:** A coordinator agent combines the findings to form global patterns. 

- **5.Learning & Adaptation:** Agents refine their strategies for future tasks. 

--- end of page.page_number=160 ---

**==> picture [480 x 423] intentionally omitted <==**

--- end of page.page_number=161 ---

## **Applications** 

- Distributed Intrusion Detection Systems 

Agents detect anomalies at local nodes and collaborate to flag threats. 

- E-commerce Recommendation Systems 

- Agents learn user preferences and exchange recommendations. 

- IoT & Sensor Networks 

Intelligent agents analyze local data streams (temperature, traffic, etc.) collaboratively. 

- Healthcare Data Mining 

Agents handle distributed patient data while maintaining privacy. 

- Web Mining & Social Networks 

Agents analyze distributed web content, link patterns, and user behavior. 

## **Challenges** 

- Communication overhead between agents 

- Data privacy and security issues 

- Knowledge integration from heterogeneous sources 

- Designing efficient agent coordination strategies 

## **Future Trends** 

- Integration with Reinforcement Learning and Deep Learning Agents 

- Federated Agent-Based Mining for privacy-preserving distributed AI 

- Real-time Edge–Cloud collaboration using intelligent agents 

--- end of page.page_number=162 ---

## **Aspect** 

Architecture Scalability Autonomy Adaptability Communication 

**Traditional Data Mining** Centralized Limited Low Static Minimal 

## **Agent-Based Mining** 

## Distributed 

## High High Dynamic 

Agent-to-agent 

--- end of page.page_number=163 ---

• Alotaibi, N. M., Abdullah, M., & Mosli, H. (2019). _Agent-based big data mining._ Retrieved from https://www.researchgate.net/publication/332763423_Agentbased_Big_Data_Mining 

• Moemeng, C., et al. (2009). _Agent-based distributed data mining: A_ In _survey._ **Distributed Data Mining and Multi-Agent Systems** (pp. 45–68). Springer. https://doi.org/10.1007/978-1-4419- 0522 2_3 

• Jamali, R., & co-authors. (2024). _Data-driven agent-based modeling: Experimenting with the integration of data mining and agent simulation. Procedia Computer Science_ , 236, 1–10. https://www.sciencedirect.com/science/article/pii/S187705092 401264X 

• Bemthuis, R. H., & Lazarova-Molnar, S. (2025). _Towards integrating process mining with agent-based modelling and simulation: State of the art and outlook. Expert Systems with Applications_ , 239, 122534. https://www.sciencedirect.com/science/article/pii/S095741742 5011935 

• Bianchi, F. M., Maiorino, E., et al. (2014). _Agent-based algorithm exploiting multiple local dissimilarities for clusters mining and knowledge discovery. arXiv preprint_ , arXiv:1409.4988. https://arxiv.org/abs/1409.4988 

--- end of page.page_number=164 ---

**Trends in Data Mining** 

--- end of page.page_number=165 ---

## **Trends in Data Mining (2025 Perspective)** 

• Data mining has evolved from simple pattern discovery in structured data to intelligent knowledge extraction from massive, heterogeneous, and real-time data streams.Modern trends emphasize automation, scalability, interpretability, and domain adaptability. 

- **Major Emerging Trends:** 

• **A. Big Data & Scalable Mining** : Mining algorithms now handle petabyte-scale data from sensors, IoT, social networks, and web logs. Distributed frameworks such as Hadoop, Spark MLlib, and Flink enable parallel data mining. Algorithms like scalable clustering (MiniBatch K-means), distributed Apriori, and parallel decision trees are widely adopted. 

• **B. Artificial Intelligence & Deep Learning Integration:** Data mining increasingly fuses with AI, machine learning, and deep learning. Neural networks (CNNs, RNNs, Transformers) are applied for complex unstructured data—text, images, speech. Mining results guide AI decision systems, creating self-learning pipelines. 

--- end of page.page_number=166 ---

• **C. Automated Data Mining / AutoML** AutoML (Automated Machine Learning) automates model selection, feature engineering, and hyperparameter tuning. Tools like Google AutoML, Auto-Sklearn, and H2O.ai reduce human bias and time for model development. 

• **D. Stream & Real-Time Data Mining** With IoT and online transactions, continuous **stream data mining** has become crucial. 

Algorithms: VFDT (Very Fast Decision Tree), MOA (Massive Online Analysis) framework. 

Applications: financial fraud detection, smart city sensors, network intrusion detection. 

• **E. Explainable & Responsible Data Mining** The focus is shifting toward explainable AI (XAI) and ethical mining. Transparent models, interpretable rules, and fairness audits are integrated into mining processes. 

Compliance with GDPR and data governance frameworks is now mandatory. 

--- end of page.page_number=167 ---

- **F. Text, Web, and Social Media Mining** 

Unstructured data dominates — nearly 80% of enterprise data is textual or multimedia.Natural Language Processing (NLP) techniques such as BERT, GPT, and T5 power text classification and sentiment mining. Social media mining uncovers trends, misinformation, and behavioral insights. 

• **G. Spatial, Temporal, and Multimedia Mining** 

Enhanced GIS and satellite systems require spatiotemporal mining for urban planning, climate, and disaster analysis. Multimedia data mining extracts visual/audio features for pattern recognition (e.g., face recognition, emotion detection). 

• **H. Cloud, Edge, and Federated Mining** 

Cloud mining offers scalability and accessibility. Edge mining processes data locally near the source (IoT/robotics) to reduce latency. Federated learning and mining ensure privacy-preserving knowledge sharing across distributed nodes. 

--- end of page.page_number=168 ---

## • **I. Agent-Based and Multi-Agent Mining** 

Autonomous intelligent agents coordinate to mine distributed, dynamic datasets. Used in robotics, IoT, and decision support systems. Enables decentralized, cooperative learning and real-time adaptation. 

• **J. Graph & Network Mining** 

Knowledge graphs and network mining reveal relationships among entities (social, biological, or web).Graph neural networks (GNNs) are the new frontier for link prediction and anomaly detection. 

• **K. Sustainable and Green Data Mining** 

Energy-efficient algorithms and eco-friendly data centers reduce the carbon footprint of large-scale mining. Research explores low-power hardware acceleration and optimal resource scheduling. 

--- end of page.page_number=169 ---

**Mining Complex Types of Data** 

--- end of page.page_number=170 ---

**Mining Complex Types of Data** 

- Multidimensional analysis and descriptive mining of complex data objects 

- Mining spatial databases 

• Mining multimedia databases 

- Mining time-series and sequence data 

- • Mining text databases 

- Mining the World-Wide Web 

--- end of page.page_number=171 ---

## **Multidimensional Analysis and Descriptive Mining of Complex Data Objects** 

- Traditional data mining techniques were designed for simple, flat, relational data. 

- Recent applications—such as scientific experiments, multimedia archives, and engineering systems—generate complex data objects that possess rich structures, semantics, and relationships. 

- Examples: 

1. CAD ((Computer-Aided Design)/CAM ((Computer-Aided Manufacturing)designs (objects with geometric and relational components), 

2. Biological data (proteins, genes with hierarchical features), 

3. Multimedia files (images, videos, sounds), 

4. Spatio-temporal trajectories (GPS or drone data). 

- Such data require multidimensional analysis for understanding patterns across different attributes (dimensions) and descriptive mining to summarize inherent structures and relationships. 

--- end of page.page_number=172 ---

## **Key Concepts** 

- **I. Complex Data Objects** 

A complex data object is one that contains: 

1. Structured attributes: nested fields, arrays, or objects within objects. 

2. Non-standard data types: images, time-series, spatial regions, text, audio, etc. 

3. Inter-object relationships: inheritance (IS-A), aggregation (HAS-A), and associations. 

Example: A “Customer” object may include personal_info, purchase_history, location_map, and clickstream_sequence. Each of these sub-objects represents a distinct data modality. 

--- end of page.page_number=173 ---

## **II. Multidimensional Analysis:** 

Multidimensional analysis involves viewing data along multiple dimensions and performing OLAP (Online Analytical Processing) operations for exploration and aggregation. 

**(a) Dimensions and Measures** 

• Dimensions: perspectives of analysis (e.g., Time, Location, Product, Customer Type). 

• Measures: quantitative attributes computed across dimensions (e.g., total sales, average dwell time, number of transactions). 

• In complex data, dimensions can also be non-numeric or structural — for example, image color category, spatial zone, or sequence length. 

--- end of page.page_number=174 ---

## **(b) OLAP (Online Analytical Processing)Operations** 

|**Operation**|**Explanation**|**Example**|
|---|---|---|
|**Roll-Up**|Summarizing data by moving<br>up the hierarchy|City → State → Country →<br>Continent (e.g., total sales per<br>continent)|
||Breaking aggregates into finer|From “State = Gujarat” → cities|
|**Drill-Down**|details i.e., exploring finer-|(Surat, Ahmedabad, Vadodara)|
||grained details|→ local sales per product|
|**Slice**|Selecting and projecting<br>specific subsets of data. Fixing<br>one dimension value to<br>analyze a single subset|Extract “Year = 2025” slice<br>from Sales cube to view all<br>region-wise data for 2025|
||Selecting a sub-cube by|Region = “West India” AND|
|**Dice**|choosing specific values from|Product = “Electronics” AND|
||multiple dimensions|Year = 2024|
|**Pivot (Rotate)**|Reorienting the cube to view<br>data along different axes i.e.,<br>viewing data from new<br>perspectives or dimensions.|Rotate from (Region × Year) to<br>(Product × Year) view to<br>compare performance by<br>product|



--- end of page.page_number=175 ---

**(c) Data Cubes for Complex Data** 

• A data cube is an n-dimensional array that stores aggregated measures for all possible combinations of dimension values. 

• For complex data: 

1. Measures may not be simple numeric counts; they can be functions, histograms, or feature vectors. 

2. Example: For multimedia data, each cube cell could store a feature centroid (e.g., average color histogram) rather than a numeric sum. 

--- end of page.page_number=176 ---

## **Descriptive Mining** 

- Descriptive data mining aims to summarize the general characteristics and structures of data without necessarily predicting a target variable. 

- It contrasts with predictive mining (e.g., classification, regression). 

- **Types of Descriptive Mining Tasks** 

**1. Concept/Attribute Generalization:** Generalizes low-level data to high-level concepts using attribute hierarchies. Example: City →State →Country“Dell Inspiron 14” →“Laptop” →“Electronics”. 

**2. Characterization:** Summarizes data belonging to a target class. Example: “High-value customers” – average spending pattern, preferred products, regional concentration. 

**3. Discrimination:** Compares characteristics of contrasting classes. Example: “Customers buying premium vs budget models”. 

**4. Clustering:** Groups objects into clusters based on similarity (e.g., image features, spatial proximity, behavioral patterns). 

**5. Association/Correlation Analysis:** Finds relationships between attributes. Example: “Customers who buy drones also buy Li-ion batteries.” 

**6. Summarization and Visualization:** Produces concise, high-level visual summaries (bar charts, cubes, heatmaps, feature clouds). 

--- end of page.page_number=177 ---

## **Integration of OLAP and Data Mining** 

• The OLAP (Online Analytical Processing) Mining integration provides a unified environment for exploratory and confirmatory analysis: 

**OLAP Function** 

Roll-up / Drill-down 

Slice / Dice 

Pivot 

Measure Aggregation 

**Descriptive Mining Extension** 

Generalization or specialization of rules or clusters 

- Selecting subsets for local pattern discovery Discovering cross-dimensional correlations Feature summarization (mean, median, centroid, etc.) 

• Example: A spatial–temporal cube for vehicle trajectories can reveal: 

1. Dimensions: Time, Location, Vehicle Type 

2. Measure: Average speed→ Patterns: “Heavy trucks exhibit reduced speed in city centers during 8–10 AM.” 

--- end of page.page_number=178 ---

**Data Representation for Complex Objects Type of Complexity Representation Model** 

**Type of Complexity Representation Model Example of Measures** Hierarchical / ObjectClass hierarchy, method Object-relational schema oriented attributes Spatial / Geometric GIS, raster/vector models Area, distance, adjacency Temporal / Sequential Time-series, event logs Duration, periodicity Feature vectors, Multimedia Texture, color histogram descriptors Term–document matrix, Textual TF–IDF, word2vec embeddings Graph / Network Node–edge structures Centrality, connectivity 

**Technique Type Captures** TF–IDF Word importance based (Term Frequency–Inverse Statistical weighting on frequency Document Frequency) Word meaning based on Word2Vec Neural embedding context 

--- end of page.page_number=179 ---

## **Challenges in Mining Complex Data** 

**1. Data Heterogeneity:** Different data types (numeric, image, audio, symbolic) require unified frameworks. 

**2. High Dimensionality:** 

   - Multimedia or sensor data involve hundreds of features → computational complexity. 

**3. Semantic Gap:** 

   - Between low-level features (pixels, waveforms) and high-level meaning (“sunset”, “emotion”). 

**4. Data Volume and Scalability:** Complex object repositories (e.g., social networks, video archives) are massive. 

**5. Indexing and Similarity Search:** 

   - Requires efficient indexing for non-traditional data (e.g., R-trees (Regional Trees), KD (K Dimensional)-trees, LSH (Locality-Sensitive Hashing)). 

**6. Integration Across Modalities:** Combining text + image + spatial + temporal aspects for richer insights. 

**7. Interpretability:** 

Extracted patterns must be human-understandable and domain-relevant. 

--- end of page.page_number=180 ---

## **Example Case Study** 

- **Application: Mining Object-Oriented Multimedia Warehouse** 

- **Scenario:** A museum maintains digital archives of artworks. Each “Artwork” object has 

   - attributes: 

      - Title, Artist, Period (text) 

      - Image (multimedia) 

      - Geographical origin (spatial) 

      - Exhibition history (temporal sequence) 

- **Goal:** Analyze patterns of art trends over centuries. 

- **Steps:** 

**1. Build a multidimensional cube** : 

   - a. Dimensions: _Time period_ , _Region_ , _Art style_ 

   - b. Measures: _Average color hue_ , _Count of artworks_ , _Popularity index_ . 

**2. Apply roll-up** to aggregate by century or continent. 

- : 

- **3. Perform descriptive mining** 

   - a. Cluster similar styles across regions. 

   - b. Discover correlations between _color palettes_ and _geographic zones_ . 

   - c. Identify temporal evolution of artistic features. 

- **Result** → Insightful understanding of art diffusion patterns. 

--- end of page.page_number=181 ---

## **Generalization of Structured Data** 

- Set-valued attribute • Generalization of each value in the set into its corresponding higher-level concepts 

   - Derivation of the general behavior of the set, such as the number of elements in the set, the types or value ranges in the set, or the weighted average for numerical data 

   - E.g., _hobby_ = { _tennis, hockey, chess, violin, nintendo_games_ } generalizes to { _sports, music, video_games_ } 

- List-valued or a sequence-valued attribute 

   - Same as set-valued attributes except that the order of the elements in the should be observed in the sequence 

   - generalization 

--- end of page.page_number=182 ---

   - **Generalizing Spatial and Multimedia Data** 

- Spatial data: • Generalize detailed geographic points into clustered regions, such as business, residential, industrial, or agricultural areas, according to land usage 

   - Require the merge of a set of geographic areas by spatial operations 

- Image data: 

   - Extracted by aggregation and/or approximation 

   - Size, color, shape, texture, orientation, and relative positions and structures of the contained objects or regions in the image 

- Music data: 

   - Summarize its melody: based on the approximate patterns that repeatedly occur in the segment 

   - Summarized its style: based on its tone, tempo, or the major musical instruments played 

--- end of page.page_number=183 ---

## **Generalizing Object Data** 

- Object identifier: generalize to the lowest level of class in the class/subclass hierarchies 

- Class composition hierarchies 

   - generalize nested structured data 

   - generalize only objects closely related in semantics to the current one 

- Construction and mining of object cubes 

   - Extend the attribute-oriented induction method 

      - Apply a sequence of class-based generalization operators on different attributes 

      - Continue until getting a small number of generalized objects that can be summarized as a concise in high-level terms 

   - For efficient implementation 

      - Examine each attribute, generalize it to simple-valued data 

      - Construct a multidimensional data cube (object cube) 

      - • Problem: it is not always desirable to generalize a set of values to single-valued data 

--- end of page.page_number=184 ---

## **A Travel Database for Plan Mining** 

## • **Example: Mining a travel plan-base** 

## Travel plans table 

**==> picture [434 x 134] intentionally omitted <==**

**----- Start of picture text -----**<br>
plan#   action#   departure    depart_time arrival   arrival_time    airline   …<br>1 1 ALB 800 JFK 900 TWA …<br>1 2 JFK 1000 ORD 1230 UA …<br>1 3 ORD 1300 LAX 1600 UA …<br>1 4 LAX 1710 SAN 1800 DAL …<br>2 1 SPI 900 ORD 950 AA …<br>. . . . . . . .<br>. . . . . . . .<br>. . . . . . . .<br>**----- End of picture text -----**<br>


## Air ort info table p 

**==> picture [324 x 129] intentionally omitted <==**

**----- Start of picture text -----**<br>
airport_code    city   state    region    airport_size …<br>1 1 ALB 800 …<br>1 2 JFK 1000 …<br>1 3 ORD 1300 …<br>1 4 LAX 1710 …<br>2 1 SPI 900 …<br>. . . . .<br>. . . . .<br>. . . . .<br>**----- End of picture text -----**<br>


--- end of page.page_number=185 ---

## **Multidimensional Analysis** 

• Strategy 

- Generalize the planbase 

in different directions • Look for sequential patterns in the generalized plans 

• Derive high-level plans 

A multi-D model for the planbase 

**==> picture [342 x 315] intentionally omitted <==**

--- end of page.page_number=186 ---

## **Generalization-Based Sequence Mining** 

• Generalize planbase in multidimensional way using dimension tables • Use of distinct values (cardinality) at each level to determine the right level of generalization (level-“planning”) • Use operators _merge_ “+”, _option_ “[]” to further generalize patterns 

• Retain patterns with significant support 

--- end of page.page_number=187 ---

**Spatial Data Warehousing** 

• Spatial data warehouse: Integrated, subject-oriented, time-variant, and nonvolatile spatial data repository for data analysis and decision making 

- Spatial data integration: a big issue 

   - Structure-specific formats (rastervs. vector-based, ObjectedOriented vs. relational models, different storage and indexing, etc.) 

   - • Vendor-specific formats (ESRI, MapInfo, Integraph, etc.) 

   - • ESRI (Environmental Systems Research Institute) is the world’s leading company in Geographic Information Systems (GIS) software. ArcGIS is their most famous GIS software 

   - • ESRI provides tools to store, analyze, visualize, and mine spatial (geographical) data. 

- Spatial data cube: multidimensional spatial database 

   - Both dimensions and measures may contain spatial components 

--- end of page.page_number=188 ---

## **Dimensions and Measures in Spatial Data Warehouse** 

- Dimension modeling 

   - nonspatial 

      - e.g. temperature: 25-30 degrees generalizes to _hot_ 

   - spatial-to-nonspatial 

      - e.g. region “B.C.” generalizes to 

         - description “ _western provinces”_ 

   - spatial-to-spatial 

      - e.g. region “Burnaby” generalizes to region “Lower Mainland” 

- Measures 

   - numerical 

      - distributive (e.g. count, 

         - sum) 

      - algebraic (e.g. average) 

      - holistic (e.g. median, rank) 

   - spatial 

      - collection of spatial 

         - pointers (e.g. pointers to all regions with 25-30 degrees 

         - in July) 

--- end of page.page_number=189 ---

## **Methods for Computation of Spatial Data Cube** 

- On-line aggregation: collect and store pointers to spatial objects in a spatial data cube 

   - expensive and slow, need efficient aggregation techniques 

- Precompute and store all the possible combinations 

   - huge space overhead 

- Precompute and store rough approximations in a spatial data cube 

   - accuracy trade-off 

- Selective computation: only materialize those which will be accessed frequently 

   - a reasonable choice 

--- end of page.page_number=190 ---

## **Similarity Search in Multimedia Data** 

- Description-based retrieval systems 

   - Build indices and perform object retrieval based on image descriptions, such as keywords, captions, size, and time of creation 

   - Labor-intensive if performed manually 

   - Results are typically of poor quality if automated 

- Content-based retrieval systems 

   - Support retrieval based on the image content, such as color histogram, texture, shape, objects, and wavelet transforms 

--- end of page.page_number=191 ---

## **Queries in Content-Based Retrieval Systems** 

- Image sample-based queries: 

   - Find all of the images that are similar to the given image sample 

   - Compare the feature vector (signature) extracted from the sample with the feature vectors of images that have already been extracted and indexed in the image database 

- Image feature specification queries: 

   - Specify or sketch image features like color, texture, or shape, which are translated into a feature vector 

   - Match the feature vector with the feature vectors of the images in the database 

--- end of page.page_number=192 ---

## **Approaches Based on Image Signature** 

- Color histogram-based signature 

   - The signature includes color histograms based on color composition of an image regardless of its scale or orientation 

   - No information about shape, location, or texture 

   - Two images with similar color composition may contain very different shapes or textures, and thus could be completely unrelated in semantics 

- Multifeature composed signature 

   - The signature includes a composition of multiple features: color histogram, shape, location, and texture 

   - Can be used to search for similar images 

--- end of page.page_number=193 ---

## **Wavelet Analysis** 

- Wavelet-based signature 

   - Use the dominant wavelet coefficients of an image as its signature 

   - Wavelets capture shape, texture, and location information in a single unified framework 

   - Improved efficiency and reduced the need for providing multiple search primitives 

   - May fail to identify images containing similar in location or size objects 

- Wavelet-based signature with region-based granularity 

   - Similar images may contain similar regions, but a region in one image could be a translation or scaling of a matching region in the other 

   - Compute and compare signatures at the granularity of regions, not the entire image 

--- end of page.page_number=194 ---

## **C-BIRD Content-Based Image Retrieval from Digital libraries** 

**==> picture [409 x 402] intentionally omitted <==**

Search  by image colors  by color percentage  by color layout  by texture density  by texture Layout  by object model  by illumination invariance  by keywords 

--- end of page.page_number=195 ---

## **Mining Multimedia Databases** 

## **Refining or combining searches** 

**==> picture [317 x 211] intentionally omitted <==**

Search for “blue sky” (top layout grid is blue) 

**==> picture [190 x 51] intentionally omitted <==**

## Search for “airplane in blue sky” (top layout grid is blue and keyword = “airplane”) 

**==> picture [128 x 51] intentionally omitted <==**

Search for “blue sky and green meadows” (top layout grid is blue and bottom is green) 

--- end of page.page_number=196 ---

## **Multidimensional Analysis of Multimedia Data** 

- Multimedia data cube 

   - Design and construction similar to that of traditional data cubes from relational data 

   - Contain additional dimensions and measures for multimedia information, such as color, texture, and shape 

- The database does not store images but their descriptors 

   - Feature descriptor: a set of vectors for each visual characteristic 

      - Color vector: contains the color histogram 

      - MFC (Most Frequent Color) vector: five color centroids 

      - MFO (Most Frequent Orientation) vector: five edge orientation centroids 

   - Layout descriptor: contains a color layout vector and an edge layout vector 

--- end of page.page_number=197 ---

## **Mining Time-Series and Sequence Data** 

- Time-series database 

   - Consists of sequences of values or events changing with time 

   - Data is recorded at regular intervals 

   - Characteristic time-series components 

      - Trend, cycle, seasonal, irregular 

- Applications 

   - Financial: stock price, inflation 

   - Biomedical: blood pressure 

   - Meteorological: precipitation 

--- end of page.page_number=198 ---

## **Mining Time-Series and Sequence Data** 

**Time-series plot** 

**==> picture [535 x 327] intentionally omitted <==**

--- end of page.page_number=199 ---

## **Mining Time-Series and Sequence Data: Trend analysis** 

- A time series can be illustrated as a time-series graph which describes a point moving with the passage of time 

- Categories of Time-Series Movements 

   - Long-term or trend movements (trend curve) 

   - Cyclic movements or cycle variations, e.g., business cycles 

   - Seasonal movements or seasonal variations 

      - i.e, almost identical patterns that a time series appears to follow during corresponding months of successive years. 

   - Irregular or random movements 

--- end of page.page_number=200 ---

## **Estimation of Trend Curve** 

- The freehand method 

   - Fit the curve by looking at the graph 

   - Costly and barely reliable for large-scaled data mining 

- The least-square method 

   - Find the curve minimizing the sum of the squares of the deviation of points on the curve from the corresponding data points 

- The moving-average method 

   - Eliminate cyclic, seasonal and irregular patterns 

   - Loss of end data 

   - Sensitive to outliers 

--- end of page.page_number=201 ---

## **Similarity Search in Time-Series Analysis** 

- Normal database query finds exact match 

- Similarity search finds data sequences that differ only slightly from the given query sequence 

- Two categories of similarity queries 

   - Whole matching: find a sequence that is similar to the query sequence 

   - Subsequence matching: find all pairs of similar sequences 

- Typical Applications 

   - Financial market 

   - Market basket data analysis 

   - Scientific databases 

   - Medical diagnosis 

--- end of page.page_number=202 ---

## **Multidimensional Indexing** 

- Multidimensional index 

   - Constructed for efficient accessing using the first few Fourier coefficients 

- Use the index can to retrieve the sequences that are at most a certain small distance away from the query sequence 

- Perform postprocessing by computing the actual distance between sequences in the time domain and discard any false matches 

--- end of page.page_number=203 ---

## **Subsequence Matching** 

- _w_ 

- Break each sequence into a set of pieces of window with length 

- Extract the features of the subsequence inside the window 

- Map each sequence to a “trail” in the feature space 

- Divide the trail of each sequence into “subtrails” and represent each of them with minimum bounding rectangle 

- Use a multipiece assembly algorithm to search for longer sequence matches 

--- end of page.page_number=204 ---

## **Enhanced similarity search methods** 

- Allow for gaps within a sequence or differences in offsets or amplitudes 

- Normalize sequences with amplitude scaling and offset translation 

- • Two subsequences are considered similar if one lies within an envelope of  width around the other, ignoring outliers 

- Two sequences are said to be similar if they have enough non-overlapping time-ordered pairs of similar subsequences 

- Parameters specified by a user or expert: sliding window size, width of an envelope for similarity, maximum gap, and matching fraction 

--- end of page.page_number=205 ---

## **Steps for performing a similarity search** 

- Atomic matching 

   - Find all pairs of gap-free windows of a small length that are similar 

- Window stitching 

   - Stitch similar windows to form pairs of large similar subsequences allowing gaps between atomic matches 

- Subsequence Ordering 

   - Linearly order the subsequence matches to determine whether enough similar pieces exist 

--- end of page.page_number=206 ---

## **Sequential Pattern Mining** 

- Mining of frequently occurring patterns related to time or other sequences 

- Sequential pattern mining usually concentrate on symbolic patterns 

- Examples 

   - Renting “Star Wars”, then “Empire Strikes Back”, then “Return of the Jedi” in that order 

   - Collection of ordered events within an interval 

- Applications 

   - Targeted marketing 

   - Customer retention 

   - Weather prediction 

--- end of page.page_number=207 ---

## **Text Databases and Information retrieval (IR)** 

- Text databases (document databases) 

   - Large collections of documents from various sources: news articles, research papers, books, digital libraries, e-mail messages, and Web pages, library database, etc. 

   - Data stored is usually _semi-structured_ 

   - Traditional information retrieval techniques become inadequate for the increasingly vast amounts of text data 

- Information retrieval 

   - A field developed in parallel with database systems 

   - Information is organized into (a large number of) documents 

   - Information retrieval problem: locating relevant documents based on user input, such as keywords or example documents 

--- end of page.page_number=208 ---

## **Information Retrieval (IR)** 

- Typical IR systems 

   - Online library catalogs 

• Online document management systems 

- Information retrieval vs. database systems 

   - Some DB problems are not present in IR, e.g., update, transaction management,  complex objects 

• Some IR problems are not addressed well in DBMS, e.g., unstructured documents, approximate search using keywords and relevance 

--- end of page.page_number=209 ---

## **Basic Measures for Text Retrieval** 

**==> picture [384 x 136] intentionally omitted <==**

• Precision: the percentage of retrieved documents that are in fact relevant to the query (i.e., “correct” responses) 

## {| _Relevant_ }  { _Retrieved_ |}  _precision_ {| _Retrieved_ |} 

• Recall: the percentage of documents that are relevant to the query and were, in fact, retrieved 

## {| _Relevant_ }  { _Retrieved_ |}  _precision_ {| _Relevant_ |} 

--- end of page.page_number=210 ---

      - **Keyword-Based Retrieval** 

- A document is represented by a string, which can be identified by a set of keywords 

- Queries may use expressions of keywords 

   - E.g., car _and_ repair shop, tea _or_ coffee, DBMS _but not_ Oracle 

   - • Queries and retrieval should consider synonyms, e.g., repair and maintenance 

- Major difficulties of the model 

   - Synonymy: A keyword _T_ does not appear anywhere in the document, even though the document is closely related to _T_ , e.g., data mining 

   - Polysemy: The same keyword may mean different things in different contexts, e.g., mining 

--- end of page.page_number=211 ---

## **Similarity-Based Retrieval in Text Databases** 

- Finds similar documents based on a set of common keywords 

- Answer should be based on the degree of relevance based on the nearness of the keywords, relative frequency of the keywords, etc. 

- Basic techniques 

- Stop list 

   - Set of words that are deemed “irrelevant”, even though they may appear frequently 

   - E.g., _a, the, of, for, with_ , etc. 

   - Stop lists may vary when document set varies 

--- end of page.page_number=212 ---

- Word stem 

   - Several words are small syntactic variants of each other since they share a 

      - common word stem 

   - E.g., _drug_ , _drugs, drugged_ 

- A term frequency table 

   - Each entry _frequent_table(i, j)_ =  # of occurrences of the word _ti_ in 

      - document _d i_ 

   - Usually, the _ratio_ instead of the absolute number of occurrences is used 

- Similarity metrics: measure the closeness of a document to a query (a set of keywords) 

   - Relative term occurrences 

   - Cosine distance: 

 _v_ 1 

_v_ 

 _v v_ 1 2  _sim_ ( _v_ 1, _v_ 2 ) _v v_ | 1 || 2 | 

--- end of page.page_number=213 ---

## **Types of Text Data Mining** 

- Keyword-based association analysis 

- Automatic document classification 

- Similarity detection 

   - Cluster documents by a common author 

   - Cluster documents containing information from a common source 

- Link analysis: unusual correlation between entities 

- Sequence analysis: predicting a recurring event 

- Anomaly detection: find information that violates usual patterns 

- Hypertext analysis 

   - Patterns in anchors/links 

      - Anchor text correlations with linked objects 

--- end of page.page_number=214 ---

## **Keyword-based association analysis** 

- Collect sets of keywords or terms that occur frequently together and then find the association or correlation relationships among them 

- First preprocess the text data by parsing, stemming, removing stop words, etc. 

- Then evoke association mining algorithms 

   - Consider each document as a transaction 

   - View a set of keywords in the document as a set of items in the transaction 

- Term level association mining 

   - No need for human effort in tagging documents 

   - The number of meaningless results and the execution time is greatly reduced 

--- end of page.page_number=215 ---

## **Automatic document classification** 

- Motivation 

   - Automatic classification for the tremendous number of on-line text documents (Web pages, e-mails, etc.) 

- A classification problem 

   - Training set: Human experts generate a training data set 

   - Classification: The computer system discovers the classification rules 

   - Application: The discovered rules can be applied to classify new/unknown documents 

- Text document classification differs from the classification of relational data • Document databases are not structured according to attribute-value pairs 

--- end of page.page_number=216 ---

## **Association-Based Document Classification** 

- Extract keywords and terms by information retrieval and simple association analysis techniques 

- Obtain concept hierarchies of keywords and terms using 

   - Available term classes, such as WordNet 

   - Expert knowledge 

   - Some keyword classification systems 

- Classify documents in the training set into class hierarchies 

- Apply term association mining method to discover sets of associated terms 

- Use the terms to maximally distinguish one class of documents from others 

- Derive a set of association rules associated with each document class 

- • Order the classification rules based on their occurrence frequency and discriminative power 

- Used the rules to classify new documents 

--- end of page.page_number=217 ---

## **Document Clustering** 

- Automatically group related documents based on their contents 

- Require no training sets or predetermined taxonomies, generate a taxonomy at runtime 

- Major steps 

   - Preprocessing 

      - Remove stop words, stem, feature extraction, lexical analysis, … 

   - Hierarchical clustering 

      - Compute similarities applying clustering algorithms, … 

   - Slicing 

      - Fan out controls, flatten the tree to configurable number of levels, … 

--- end of page.page_number=218 ---

## **Mining the World-Wide Web (WWW)** 

- The WWW is huge, widely distributed, global information service center for • Information services: news, advertisements, consumer information, financial management, education, government, e-commerce, etc. 

   - Hyper-link information 

   - Access and usage information 

- WWW provides rich sources for data mining 

- Challenges 

   - Too huge for effective data warehousing and data mining 

   - Too complex and heterogeneous: no standards and structure 

--- end of page.page_number=219 ---

## **Mining the World-Wide Web** 

• Growing and changing very rapidly 

## **Internet growth** 

|0<br>5000000<br>10000000<br>15000000<br>20000000<br>25000000<br>30000000<br>35000000<br>40000000<br><br>**Hosts**|Sep-69<br>Sep-72<br>Sep-75<br>Sep-78<br>Sep-81<br>Sep-84<br>Sep-87<br>Sep-90<br>Sep-93<br>Sep-96<br>Sep-99|
|---|---|



• Broad diversity of user communities 

- Only a small portion of the information on the Web is truly relevant or useful 

• 99% of the Web information is useless to 99% of Web users 

- How can we find high-quality Web pages on a specified topic? 

--- end of page.page_number=220 ---

## **Web search engines** 

- Index-based: search the Web, index Web pages, and build and store huge keyword-based indices 

- Help locate sets of Web pages containing certain keywords 

- Deficiencies 

   - A topic of any breadth may easily contain hundreds of thousands of documents 

   - Many documents that are highly relevant to a topic may not contain keywords defining them (polysemy) 

--- end of page.page_number=221 ---

## **Web Mining** 

- Searches for 

   - Web access patterns 

   - Web structures 

   - Regularity and dynamics of Web contents 

- Problems 

   - The “abundance” problem 

   - Limited coverage of the Web: hidden Web sources,  majority of data in DBMS 

   - Limited query interface based on keyword-oriented search 

   - Limited customization to individual users 

--- end of page.page_number=222 ---

## **Web Mining Taxonomy** 

**==> picture [517 x 217] intentionally omitted <==**

**----- Start of picture text -----**<br>
Web Mining<br>Web Content Web Structure Web Usage<br>Mining Mining Mining<br>Web Page Search Result General Access Customized<br>Content Mining Mining Pattern Tracking Usage Tracking<br>**----- End of picture text -----**<br>


--- end of page.page_number=223 ---

## **Mining the World-Wide Web** 

**==> picture [371 x 217] intentionally omitted <==**

**----- Start of picture text -----**<br>
Web Mining<br>Web Structure<br>Web Usage<br>Mining<br>Mining<br>Search Result General Access Customized<br>Mining Pattern Tracking Usage Tracking<br>**----- End of picture text -----**<br>


**==> picture [103 x 49] intentionally omitted <==**

**----- Start of picture text -----**<br>
Web Content<br>Mining<br>**----- End of picture text -----**<br>


## Web Page Content Mining 

**Web Page Summarization** 

WebLog (Lakshmanan et.al. 1996), WebOQL(Mendelzon et.al. 1998) …: Web Structuring query languages; Can identify information within given web pages 

•Ahoy! (Etzioni et.al. 1997):Uses heuristics 

- to distinguish personal home pages from other web pages 

- ShopBot (Etzioni et.al. 1997): Looks for 

- product prices within web pages 

--- end of page.page_number=224 ---

## **Mining the World-Wide Web** 

**==> picture [629 x 217] intentionally omitted <==**

**----- Start of picture text -----**<br>
Web Mining<br>Web Content<br>Web Structure<br>Mining Web Usage<br>Mining<br>Mining<br>Web Page<br>Content Mining<br>Search Result Mining<br>General Access Customized<br>Search Engine Result  Pattern Tracking Usage Tracking<br>**----- End of picture text -----**<br>


**Search Engine Result Summarization** •Clustering Search Result ( _Leouski and Croft, 1996, Zamir and Etzioni, 1997_ ): Categorizes documents using phrases in titles and snippets 

--- end of page.page_number=225 ---

## **Mining the World-Wide Web** 

|||||||Web Mining||||||
|---|---|---|---|---|---|---|---|---|---|---|---|
|||||||||||||
||Web Content|||||||||Web Usage||
||Mining|||||Web Structure Mining||||Mining||
|||||||**Using Links**||||||
|||||||•PageRank (Brin et al., 1998)||||||
|||||||•CLEVER (Chakrabarti et al., 1998)||||||
|||Search Result||||Use interconnections between web pages to give|||General Access|||
|||Mining||||weight to pages.|||Pattern Tracking|||
|||||||||||||
|Web Page||||||**Using Generalization**|||||Customized|
|Content Mining||||||•MLDB (1994),VWV (1998)|||||Usage Tracking|
|||||||Uses a multi-level database representation of the||||||
|||||||Web. Counters (popularity) and link lists are used||||||
|||||||for capturing structure.||||||



--- end of page.page_number=226 ---

## **Mining the World-Wide Web** 

**==> picture [647 x 349] intentionally omitted <==**

**----- Start of picture text -----**<br>
Web Mining<br>Web Content Web Structure Web Usage<br>Mining Mining Mining<br>Web Page Customized<br>General Access Pattern Tracking<br>Content Mining Usage Tracking<br>•Web Log Mining (Zaïane, Xin and Han, 1998)<br>Search Result<br>Mining Uses KDD techniques to understand general<br>access patterns and trends.<br>Can shed light on better structure and<br>grouping of resource providers.<br>**----- End of picture text -----**<br>


--- end of page.page_number=227 ---

## **Mining the World-Wide Web** 

Web Mining 

Web Content Web Structure Mining Mining 

Web Usage Mining 

Web Page Content Mining 

Search Result Mining 

General Access Pattern Tracking 

Customized Usage Tracking 

•Adaptive Sites (Perkowitz and Etzioni, 1997) Analyzes access patterns of each user at a time. Web site restructures itself automatically by learning from user access patterns. 

--- end of page.page_number=228 ---

## **Mining the Web's Link Structures** 

- Finding authoritative Web pages 

   - Retrieving pages that are not only relevant, but also of high quality, or authoritative on the topic 

- Hyperlinks can infer the notion of authority 

   - The Web consists not only of pages, but also of hyperlinks pointing from one page to another 

   - These hyperlinks contain an enormous amount of latent human annotation 

   - A hyperlink pointing to another Web page, this can be considered as the author's endorsement of the other page 

--- end of page.page_number=229 ---

- Problems with the Web linkage structure 

   - Not every hyperlink represents an endorsement 

      - Other purposes are for navigation or for paid advertisements 

      - If the majority of hyperlinks are for endorsement, the collective opinion will still dominate 

   - One authority will seldom have its Web page point to its rival authorities in the same field 

   - Authoritative pages are seldom particularly descriptive 

• Hub 

- Set of Web pages that provides collections of links to authorities 

--- end of page.page_number=230 ---

## **Automatic Classification of Web Documents** 

- Assign a class label to each document from a set of predefined topic categories 

- Based on a set of examples of preclassified documents 

- Example 

   - Use Yahoo!'s taxonomy and its associated documents as training and test sets 

   - Derive a Web document classification scheme 

   - Use the scheme classify new Web documents by assigning categories from the same taxonomy 

- Keyword-based document classification methods 

- Statistical models 

--- end of page.page_number=231 ---

Layern 

... 

Layer1 

Layer0 

## **Multiple Layered Web Architecture** 

## More Generalized Descriptions 

Generalized Descriptions 

--- end of page.page_number=232 ---

## **Mining the World-Wide Web** 

Layer-0: Primitive data 

Layer-1: dozen database relations representing types of objects (metadata) 

_document, organization, person, software, game, map, image,…_ 

• **document** (file_addr, authors, title, publication, publication_date, abstract, language, table_of_contents, category_description, keywords, index, multimedia_attached, num_pages, format, first_paragraphs, size_doc, timestamp, access_frequency, links_out,...) 

• **person** (last_name, first_name, home_page_addr, position, picture_attached, phone, e- mail, office_address, education, research_interests, publications, size_of_home_page, timestamp, access_frequency, ...) 

• **image** (image_addr, author, title, publication_date, category_description, keywords, size, width, height, duration, format, parent_pages, colour_histogram, Colour_layout, Texture_layout, Movement_vector, localisation_vector, timestamp, access_frequency, ...) 

--- end of page.page_number=233 ---

## Layer-2: simplification of layer-1 

• **doc_brief** (file_addr, authors, title, publication, publication_date, abstract, language, category_description, key_words, major_index, num_pages, format, size_doc, access_frequency, links_out) 

• **person_brief** (last_name, first_name, publications,affiliation, e-mail, research_interests, size_home_page, access_frequency) 

Layer-3: generalization of layer-2 

• **cs_doc** (file_addr, authors, title, publication, publication_date, abstract, language, category_description, keywords, num_pages, form, size_doc, links_out) 

• **doc_summary** (affiliation, field, publication_year, count, first_author_list, file_addr_list) 

- **doc_author_brief** (file_addr, authors, affiliation, title, publication, pub_date, 

- category_description, keywords, num_pages, format, size_doc, links_out) 

- **person_summary** (affiliation, research_interest, year, num_publications, count) 

--- end of page.page_number=234 ---

## **Web Usage Mining** 

- Mining Web log records to discover user access patterns of Web pages 

- Applications 

   - Target potential customers for electronic commerce 

   - Enhance the quality and delivery of Internet information services to the end user 

   - Improve Web server system performance 

   - Identify potential prime advertisement locations 

- Web logs provide rich information about Web dynamics 

   - Typical Web log entry includes the URL requested, the IP address from which the request originated, and a timestamp 

--- end of page.page_number=235 ---

## **Techniques for Web usage mining** 

- Construct multidimensional view on the Weblog database 

   - Perform multidimensional OLAP analysis to find the top _N_ users, top _N_ accessed Web pages, most frequently accessed time periods, etc. 

- Perform data mining on Weblog records 

   - Find association patterns, sequential patterns, and trends of Web accessing 

   - • May need additional information,e.g., user browsing sequences of the Web pages in the Web server buffer 

- Conduct studies to 

   - Analyze system performance, improve system design by Web caching, Web page prefetching, and Web page swapping 

--- end of page.page_number=236 ---

## **Mining the World-Wide Web** 

- Design of a Web Log Miner 

   - Web log is filtered to generate a relational database 

   - A data cube is generated form database 

   - OLAP (Online Analytical Processing) Mis used to drill-down and roll-up in the cube 

   - OLAM (Online Analytical Mining) is used for mining interesting knowledge 

**==> picture [518 x 161] intentionally omitted <==**

**----- Start of picture text -----**<br>
Knowledge<br>Database Data Cube<br>Sliced and diced<br>cube<br>1<br>2<br>3 4<br>Data Cleaning<br>Data Cube<br>OLAP Data Mining<br>Creation<br>**----- End of picture text -----**<br>


Web log 

**==> picture [61 x 73] intentionally omitted <==**

--- end of page.page_number=237 ---

**Reference** 

• References for slides 182-238 – Book: Data Mining: Concepts and Techniques by Jiawei Han and Micheline Kamber. 

--- end of page.page_number=238 ---

